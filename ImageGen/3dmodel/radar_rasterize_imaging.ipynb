{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加库函数\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "from pytorch3d.utils import ico_sphere\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pytorch3d.renderer import (\n",
    "    FoVPerspectiveCameras, look_at_view_transform, look_at_rotation, \n",
    "    RasterizationSettings, MeshRenderer, MeshRasterizer, BlendParams,\n",
    "    SoftSilhouetteShader, HardPhongShader, PointLights, TexturesVertex,OrthographicCameras\n",
    ")\n",
    "from pytorch3d.vis.plotly_vis import plot_batch_individually\n",
    "from pytorch3d.ops.points_normals import estimate_pointcloud_normals\n",
    "from pytorch3d.ops.mesh_face_areas_normals import mesh_face_areas_normals\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_pointcloud(mesh, title=\"\"):\n",
    "    # Sample points uniformly from the surface of the mesh.\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter3D(x, z, -y)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(90, 90)\n",
    "    ax.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "def plot_pointclouds_rotation(mesh, title = \"\"):\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    # 创建 3D 图形\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        z=z, \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2  # 设置点的大小\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    # 更新布局\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title='X label',\n",
    "        yaxis_title='Y label',\n",
    "        zaxis_title='Z label'                                                                                                               \n",
    "    ))\n",
    "\n",
    "    # 显示图形\n",
    "    fig.show()\n",
    "    # 将图形保存为html文件\n",
    "    fig.write_html(title+\".html\")\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# Set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:3\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: CPU only, this will be slow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入一个模型\n",
    "# trg_obj = 'Geographos Radar-based, low-res(1).obj'\n",
    "# trg_obj = 'Castalia Radar-based.obj'\n",
    "trg_obj = 'Toutatis Radar-based.obj'\n",
    "# trg_obj = 'wx_origin.obj'\n",
    "# trg_obj = 'Arrokoth Stern 2019.obj'\n",
    "\n",
    "# trg_obj = 'dolphin.obj'\n",
    "# 读取卫星各项参数\n",
    "# We read the target 3D model using load_obj\n",
    "verts, faces, aux = load_obj(trg_obj)\n",
    "\n",
    "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "# For this tutorial, normals and textures are ignored.\n",
    "faces_idx = faces.verts_idx.to(device)\n",
    "verts = verts.to(device)\n",
    "\n",
    "# We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "# (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "# Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "center = verts.mean(0)\n",
    "# # 平均直径\n",
    "mean_diameter = 2.56e3\n",
    "verts = verts - center\n",
    "scale = max(verts.abs().max(0)[0])\n",
    "verts = verts / scale\n",
    "# # 将模型绕X轴旋转90度\n",
    "# R = torch.tensor([[1, 0, 0],\n",
    "#                   [0, 0, -1],\n",
    "#                   [0, 1, 0]], dtype=torch.float32).to(device)\n",
    "# verts = verts @ R\n",
    "# # 将模型绕Y轴旋转90度\n",
    "# R = torch.tensor([[0, 0, 1],\n",
    "#                   [0, 1, 0],\n",
    "#                   [-1, 0, 0]], dtype=torch.float32).to(device)\n",
    "# verts = verts @ R\n",
    "# We construct a Meshes structure for the target mesh\n",
    "trg_mesh = Meshes(verts=[verts], faces=[faces_idx])\n",
    "\n",
    "\n",
    "# 为mesh添加材质信息\n",
    "verts_rgb = torch.ones_like(trg_mesh.verts_packed())*255  # 使用纯白色作为默认颜色\n",
    "verts_rgb = verts_rgb.unsqueeze(0)\n",
    "textures = TexturesVertex(verts_features=verts_rgb)\n",
    "trg_mesh.textures = textures\n",
    "src_mesh = trg_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建初始模型，球形\n",
    "# sphere1 = ico_sphere(4, device)\n",
    "# sphere2 = ico_sphere(4, device)\n",
    "\n",
    "# # 平移第二个球体，使它与第一个球体黏连\n",
    "# # 获取第一个球体的最大 x 坐标\n",
    "# max_x = sphere1.verts_packed()[:, 0].max()\n",
    "\n",
    "# # 获取第二个球体的顶点并进行x方向平移\n",
    "# shift = max_x - 0.1  # 确保轻微重叠\n",
    "# verts2 = sphere2.verts_packed() + torch.tensor([shift, 0, 0], device=device)\n",
    "\n",
    "# # 获取第一个球体的顶点并且平移\n",
    "# verts1 = sphere2.verts_packed() + torch.tensor([-shift, 0, 0], device=device)\n",
    "\n",
    "# # 合并两球体的顶点\n",
    "# verts = torch.cat([verts1, verts2], dim=0)\n",
    "\n",
    "# # 将两球质点平移\n",
    "# # verts = verts + torch.tensor([0, 0, 0.8], device=device)\n",
    "\n",
    "# # 合并面片，并更新第二个球体的面片索引\n",
    "# faces1 = sphere1.faces_packed()\n",
    "# faces2 = sphere2.faces_packed() + sphere1.verts_packed().shape[0]  # 更新索引\n",
    "\n",
    "# # 合并面片数据\n",
    "# faces = torch.cat([faces1, faces2], dim=0)\n",
    "\n",
    "# # 将模型绕Y轴旋转90度\n",
    "# R = torch.tensor([[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [-1.0, 0.0, 0.0]], device=device)\n",
    "# verts = verts @ R\n",
    "\n",
    "\n",
    "# # 创建黏连的球体网格\n",
    "# src_mesh = Meshes(verts=[verts], faces=[faces])\n",
    "\n",
    "\n",
    "# verts = src_mesh.verts_packed()\n",
    "# faces = src_mesh.faces_packed()\n",
    "# scaled_verts = verts * 0.5\n",
    "\n",
    "# src_mesh = Meshes(verts=[scaled_verts], faces=[faces])\n",
    "\n",
    "# 绘制初始情况下的src_mesh\n",
    "plot_pointcloud(src_mesh, \"Source mesh\")\n",
    "trg_mesh = src_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入大小为[1,3]初始向量vec，大小分别为[1]旋转轴axis_x,axis_y,axis_z，大小为[num,1]的旋转角度theta，输出大小为[num,3]的旋转后向量\n",
    "def vec_rot(vec,axis_x,axis_y,axis_z,theta):\n",
    "\n",
    "    axis_x = axis_x.expand(theta.shape)\n",
    "    axis_y = axis_y.expand(theta.shape)\n",
    "    axis_z = axis_z.expand(theta.shape)\n",
    "\n",
    "    c = torch.cos(theta)\n",
    "    s = torch.sin(theta)\n",
    "    one_c = 1 - c\n",
    "\n",
    "    Rotmat = torch.stack([\n",
    "        torch.stack([axis_x**2 * one_c + c, axis_x * axis_y * one_c - axis_z * s, axis_x * axis_z * one_c + axis_y * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_y * one_c + axis_z * s, axis_y**2 * one_c + c, axis_y * axis_z * one_c - axis_x * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_z * one_c - axis_y * s, axis_y * axis_z * one_c + axis_x * s, axis_z**2 * one_c + c], dim=-1)\n",
    "    ], dim=-2)\n",
    "\n",
    "    vec_rot = torch.matmul(Rotmat,vec.unsqueeze(1)).squeeze(2)\n",
    "\n",
    "    return vec_rot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制造可视化模型\n",
    "class visible_mesh(nn.Module):\n",
    "    def __init__(self,device) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,mesh,RadarLos):\n",
    "        batch = RadarLos.shape[0]\n",
    "        face_num = mesh.faces_packed().shape[0]\n",
    "        face_mask = torch.zeros((batch,face_num),dtype=bool,device=self.device)\n",
    "        # 计算由函数look_at_view_transform得到的旋转矩阵和平移矩阵\n",
    "        at = torch.tensor([0.0, 0.0, 0.0], device=device).expand(RadarLos.shape)\n",
    "        up = torch.tensor([0.0, 1.0, 0.0], device=device).expand(RadarLos.shape)\n",
    "\n",
    "        R, T = look_at_view_transform(eye=RadarLos*3, at=at, up=up)\n",
    "        # 生成渲染器\n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=1024, \n",
    "            blur_radius=0.0, \n",
    "            faces_per_pixel=1, \n",
    "        )\n",
    "        # 生成相机\n",
    "        cameras = OrthographicCameras(device=self.device, R=R, T=T)\n",
    "        # 生成栅格化器\n",
    "        rasterizer = MeshRasterizer(\n",
    "            cameras=cameras,\n",
    "            raster_settings=raster_settings\n",
    "        )\n",
    "        fragments = rasterizer(mesh.extend(batch))\n",
    "        # 在并行处理时，一个batch中的不同mesh有不同的面标识，但这些面标识有规律的从小到大排列,因此可以直接Unique\n",
    "        p2f = fragments.pix_to_face\n",
    "        p2f_mask = p2f[p2f>=0]\n",
    "        p2f_mask_unique = torch.unique(p2f_mask)\n",
    "        face_mask = face_mask.view(-1)\n",
    "        face_mask[p2f_mask_unique] = True\n",
    "        face_mask = face_mask.view(batch,-1)\n",
    "\n",
    "        all_faces = mesh.faces_packed()\n",
    "        all_verts = mesh.verts_packed() \n",
    "        # 利用面掩码生成批次索引\n",
    "        batch_size, num_faces = face_mask.shape\n",
    "        faces_batch = [all_faces[m] for m in face_mask]\n",
    "        verts_batch = [all_verts] * batch_size  # 假设每个 batch 使用同样的顶点\n",
    "        # 直接创建 Meshes 对象\n",
    "        Meshes_new = Meshes(verts=verts_batch, faces=faces_batch)\n",
    "        # plot_pointcloud(Meshes_new[0], \"Visible mesh\")\n",
    "\n",
    "        return Meshes_new\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得相机位置和视线位置对应的旋转矩阵\n",
    "\n",
    "def get_normals(meshes):\n",
    "    verts_packed = meshes.verts_packed()  # (V, 3)\n",
    "    faces_packed = meshes.faces_packed()  # (F, 3)\n",
    "\n",
    "    # 获取每个面的顶点\n",
    "    faces_verts = verts_packed[faces_packed]  # (F, 3, 3)\n",
    "\n",
    "    # 计算叉乘，获取法向量\n",
    "    face_normals = torch.cross(\n",
    "        faces_verts[:, 1] - faces_verts[:, 0],\n",
    "        faces_verts[:, 2] - faces_verts[:, 0],\n",
    "        dim=1\n",
    "    )\n",
    "\n",
    "    # 归一化法向量\n",
    "    face_normals = face_normals / (face_normals.norm(dim=1, keepdim=True) + 1e-6)\n",
    "\n",
    "    # face_normals 现在是每个面的法向量\n",
    "    return face_normals\n",
    "\n",
    "def rr2rd(meshes, doppler_vec, dopplercoefficient):\n",
    "    verts_list = meshes.verts_list()\n",
    "    faces_list = meshes.faces_list()\n",
    "    # 将dopplercorfficient转换为list\n",
    "    dopplercoefficient = dopplercoefficient.tolist()\n",
    "\n",
    "    # 确保 doppler_vec 的长度等于 verts_list 的长度\n",
    "    if len(doppler_vec) != len(verts_list):\n",
    "        raise ValueError(\"Length of doppler_vec must match number of vertex lists\")\n",
    "    # print(doppler_vec)\n",
    "    # print(verts_list.shape)\n",
    "    projection_list = [\n",
    "        (verts @ doppler_vec[i].unsqueeze(1)) * doppler_vec[i].unsqueeze(1).T\n",
    "        for i, verts in enumerate(verts_list)\n",
    "    ]\n",
    "    \n",
    "    scaled_projection = [proj * coefficient for proj,coefficient in zip(projection_list,dopplercoefficient)]\n",
    "    scaled_verts_list = [verts + (scaled - proj) for verts, scaled, proj in zip(verts_list, scaled_projection, projection_list)]\n",
    "\n",
    "    # 创建新的 Meshes 对象\n",
    "    meshes_scaled = Meshes(verts=scaled_verts_list, faces=faces_list)\n",
    "\n",
    "    return meshes_scaled\n",
    "\n",
    "def angel2vec(ele,azi):\n",
    "    elev_rad = torch.deg2rad(ele)\n",
    "    azim_rad = torch.deg2rad(azi)\n",
    "    \n",
    "    direction_vector = torch.stack([\n",
    "        torch.cos(elev_rad) * torch.sin(azim_rad),\n",
    "        torch.sin(elev_rad),\n",
    "        torch.cos(elev_rad) * torch.cos(azim_rad)\n",
    "    ],dim=-1)\n",
    "\n",
    "    return direction_vector\n",
    "\n",
    "class mesh_radar_render(nn.Module):\n",
    "    def __init__(self,device) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self,meshes,radarlos,omega_vec,omega,dopplercoefficient):\n",
    "\n",
    "        # 输入为 mesh [batch]\n",
    "        # radarlos [batch,3]\n",
    "        # omega_vec [batch,3]\n",
    "        # omega [batch]\n",
    "        # dopplercoefficient [batch]\n",
    "        # 输出为 image [batch,100,100]\n",
    "\n",
    "        # from opts import config_parser\n",
    "        # parser = config_parser()\n",
    "        # args = parser.parse_args()\n",
    "\n",
    "        # 多普勒轴\n",
    "        doppler_vec = torch.linalg.cross(radarlos,omega_vec)\n",
    "        # 对doppler_vec进行归一化\n",
    "        doppler_vec = doppler_vec / (torch.linalg.norm(doppler_vec,dim=-1).unsqueeze(-1) + 1e-6)\n",
    "        # 生成成像方向\n",
    "        image_vec = torch.linalg.cross(radarlos,doppler_vec)\n",
    "        # 计算由函数look_at_view_transform得到的旋转矩阵和平移矩阵\n",
    "        at = torch.tensor([0.0, 0.0, 0.0], device=device).expand(radarlos.shape)\n",
    "\n",
    "        R, T = look_at_view_transform(eye=image_vec*3*mean_diameter, at=at, up=radarlos)\n",
    "        cameras = OrthographicCameras(device=device, R=R, T=T)\n",
    "        # 获得法向量\n",
    "        normals = get_normals(meshes)\n",
    "        # 对mesh进行变换到多普勒域\n",
    "        meshes_scaled = rr2rd(meshes,doppler_vec,dopplercoefficient)\n",
    "        # 渲染\n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=(100,100), \n",
    "            blur_radius=0, \n",
    "            faces_per_pixel=3,\n",
    "        )\n",
    "        rasterizer=MeshRasterizer(\n",
    "            cameras=cameras, \n",
    "            raster_settings=raster_settings\n",
    "        )\n",
    "        fragments = rasterizer(meshes_scaled)\n",
    "        # print(fragments.pix_to_face.shape)\n",
    "        # print(fragments.pix_to_face[0,50,:,:])\n",
    "        image_temp = torch.sum(fragments.pix_to_face[0,:,:,:],dim=-1)\n",
    "        image_temp = torch.rot90(image_temp,k=1,dims=(0,1))\n",
    "        # plt.imshow(image_temp.detach().cpu().numpy())\n",
    "        # # 将生成图片不带坐标轴的保存\n",
    "        # plt.axis('off')\n",
    "        # plt.savefig('image_temp.png',bbox_inches='tight',pad_inches=0)\n",
    "        # plt.close()\n",
    "        # 计算法向量，并消除不合法的索引和负值\n",
    "        zero_vector = torch.zeros(1, 3, device=self.device)\n",
    "        normal_batch = torch.where(\n",
    "            fragments.pix_to_face[...,None] == -1,                      # 添加维度适配零向量\n",
    "            zero_vector,                               # 用零向量替换不合法的索引\n",
    "            normals[fragments.pix_to_face.clamp_min(0)]                  # 使用 torch.clamp_min 防止负值索引\n",
    "        )\n",
    "        # # 计算每一点沿视线方向到原点的距离\n",
    "        # print(fragments.bary_coords.shape)\n",
    "        # print(radarlos.shape)\n",
    "        # range1 = torch.sum(fragments.bary_coords*radarlos.unsqueeze(1).unsqueeze(2).unsqueeze(3),dim=-1)\n",
    "        # range1 = torch.where(\n",
    "        #     fragments.pix_to_face[...,None] == -1,\n",
    "        #     zero_vector,\n",
    "        #     torch.sum(fragments.bary_coords*radarlos.unsqueeze(1).unsqueeze(2).unsqueeze(3),dim=-1)\n",
    "        # )\n",
    "        # print(range1.shape)\n",
    "        # # 计算雷达坐标\n",
    "        # length = 9e5\n",
    "        # radarposition = -length*radarlos\n",
    "        # range_phase = \n",
    "        # # 计算range1对应的相位，由于目标经过缩比，等效的波长为0.03m/100\n",
    "        # lambda0 = torch.tensor(0.03/100,device=self.device)\n",
    "        # # 由于\n",
    "        # phase = torch.exp(-1j*4*math.pi*range1/lambda0)\n",
    "        # image_phase = torch.sum(phase,dim=-1)\n",
    "        # print(image_phase.shape)\n",
    "        image = torch.sum(normal_batch*radarlos.unsqueeze(1).unsqueeze(2).unsqueeze(3),dim=-1)\n",
    "        # 删除image中的所有负值\n",
    "        image = torch.nn.functional.relu(image)\n",
    "        image = torch.sum(image,dim = -1)\n",
    "\n",
    "        return image\n",
    "\n",
    "def vec_rot(vec,axis_x,axis_y,axis_z,theta):\n",
    "\n",
    "    axis_x = axis_x.expand(theta.shape)\n",
    "    axis_y = axis_y.expand(theta.shape)\n",
    "    axis_z = axis_z.expand(theta.shape)\n",
    "\n",
    "    c = torch.cos(theta)\n",
    "    s = torch.sin(theta)\n",
    "    one_c = 1 - c\n",
    "\n",
    "    Rotmat = torch.stack([\n",
    "        torch.stack([axis_x**2 * one_c + c, axis_x * axis_y * one_c - axis_z * s, axis_x * axis_z * one_c + axis_y * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_y * one_c + axis_z * s, axis_y**2 * one_c + c, axis_y * axis_z * one_c - axis_x * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_z * one_c - axis_y * s, axis_y * axis_z * one_c + axis_x * s, axis_z**2 * one_c + c], dim=-1)\n",
    "    ], dim=-2)\n",
    "\n",
    "    vec_rot = torch.matmul(Rotmat,vec.unsqueeze(1)).squeeze(2)\n",
    "\n",
    "    return vec_rot\n",
    "\n",
    "\n",
    "def Radarview_generate():\n",
    "\n",
    "    # 接下来的所有操作都在z-x-y坐标系下进行\n",
    "    \n",
    "    modelselect = 8\n",
    "    if modelselect == 1:\n",
    "        # 小行星视线方向及转轴生成\n",
    "        # batchsize\n",
    "        batch = 60\n",
    "        # 生成多组初始雷达视线方向\n",
    "        theta_losnum = 5\n",
    "        theta_los = torch.linspace(-math.pi/3,math.pi/3,theta_losnum).to(device)\n",
    "        radarlos_origin = torch.tensor(([0,0,-1.0]), device=device)\n",
    "        omega_vec_origin = torch.tensor(([1.0,0.0,0.0]), device=device)\n",
    "        RadarLos = vec_rot(radarlos_origin,omega_vec_origin[0],omega_vec_origin[1],omega_vec_origin[2],theta_los)\n",
    "        # 生成多组旋转角度\n",
    "        theta = torch.linspace(0,2*math.pi,batch).to(device)\n",
    "        # 生成多组转轴\n",
    "        omega_vec_origin1 = torch.tensor(([0.0,1.0,0.0]), device=device)\n",
    "        omega_vec = vec_rot(omega_vec_origin1,omega_vec_origin[0],omega_vec_origin[1],omega_vec_origin[2],theta_los)\n",
    "        # 得到雷达视线方向\n",
    "        Round_radar_los_all = torch.zeros((batch*RadarLos.shape[0],3),device=device)\n",
    "        Round_radar_los_real_all = torch.zeros((batch*RadarLos.shape[0],3),device=device)\n",
    "        omega_vec_all = torch.zeros((batch*omega_vec.shape[0],3),device=device)\n",
    "        for i,j in zip(range(RadarLos.shape[0]),range(omega_vec.shape[0])):\n",
    "                Round_radar_los = vec_rot(RadarLos[i],omega_vec[j,0],omega_vec[j,1],omega_vec[j,2],-theta)\n",
    "                Round_radar_los_all[batch*i:batch*(i+1)] = Round_radar_los\n",
    "                Round_radar_los_real_all[batch*i:batch*(i+1)] = vec_rot(RadarLos[i],omega_vec[j,0],omega_vec[j,1],omega_vec[j,2],theta)\n",
    "                print(omega_vec[j])\n",
    "                omega_vec_all[batch*j:batch*(j+1)] = omega_vec[j].expand(batch,3)\n",
    "        # 转速\n",
    "        omega = torch.tensor([1.0],device=device).expand(Round_radar_los_all.shape[0])\n",
    "    if modelselect == 2:\n",
    "        # tomosar视线方向及转轴生成\n",
    "        # batchsize\n",
    "        batch = 32\n",
    "        # 生成一组初始雷达视线方向\n",
    "        RadarLos = torch.tensor(([0,0,-1.0]), device=device)\n",
    "        # 生成多组旋转角度\n",
    "        theta = torch.linspace(-math.pi/3,-math.pi/6,batch).to(device)\n",
    "        # 生成一组转轴\n",
    "        omega_vec = torch.tensor(([0.0,1.0,0.0]), device=device)\n",
    "        # 生成一组雷达视线旋转转轴\n",
    "        rotation_vec = torch.tensor(([1.0,0.0,0.0]), device=device)\n",
    "        Round_radar_los_all = vec_rot(RadarLos,rotation_vec[0],rotation_vec[1],rotation_vec[2],-theta)\n",
    "        Round_radar_los_real_all = Round_radar_los_all\n",
    "        omega_vec_all = omega_vec.expand(batch,3)\n",
    "        # 转速\n",
    "        omega = torch.tensor([1.0],device=device).expand(Round_radar_los_all.shape[0])\n",
    "    if modelselect == 4:\n",
    "        # 小行星视线方向及转轴生成\n",
    "        # batchsize\n",
    "        batch = 30\n",
    "        # 生成多组初始雷达视线方向\n",
    "        RadarLos = torch.tensor(([-1.0,0.0,0.0],[-math.sqrt(3)/2,0.0,1/2],[-math.sqrt(3)/2,0.0,-1/2]), device=device)\n",
    "        # 生成多组旋转角度\n",
    "        theta = torch.linspace(0,2*math.pi,batch).to(device)\n",
    "        # 生成多组转轴\n",
    "        omega_vec = torch.tensor(([0.0,0.0,1.0],[0.0,0.0,1.0],[0.0,0.0,1.0]), device=device)\n",
    "        # 得到雷达视线方向\n",
    "        Round_radar_los_all = torch.zeros((batch*RadarLos.shape[0],3),device=device)\n",
    "        Round_radar_los_real_all = torch.zeros((batch*RadarLos.shape[0],3),device=device)\n",
    "        omega_vec_all = torch.zeros((batch*omega_vec.shape[0],3),device=device)\n",
    "        for i,j in zip(range(RadarLos.shape[0]),range(omega_vec.shape[0])):\n",
    "                Round_radar_los = vec_rot(RadarLos[i],omega_vec[j,0],omega_vec[j,1],omega_vec[j,2],-theta)\n",
    "                Round_radar_los_all[batch*i:batch*(i+1)] = Round_radar_los\n",
    "                Round_radar_los_real_all[batch*i:batch*(i+1)] = vec_rot(RadarLos[i],omega_vec[j,0],omega_vec[j,1],omega_vec[j,2],theta)\n",
    "                omega_vec_all[batch*j:batch*(j+1)] = omega_vec[j].expand(batch,3)\n",
    "        # 转速\n",
    "        omega = torch.tensor([1.0],device=device).expand(Round_radar_los_all.shape[0])\n",
    "    if modelselect == 3:\n",
    "        # 小行星视线方向及转轴生成\n",
    "        # batchsize\n",
    "        batch = 30\n",
    "        # 生成多组初始雷达视线方向\n",
    "        RadarLos = torch.tensor(([-1.0,0.0,0.0],[-math.sqrt(3)/2,0.0,1/2],[-math.sqrt(3)/2,0.0,-1/2]), device=device)\n",
    "        # 生成多组旋转角度\n",
    "        theta = torch.linspace(0,2*math.pi,batch).to(device)\n",
    "        # 生成多组转轴\n",
    "        omega_vec = torch.tensor(([0.0,0.0,1.0],[1/2,0,math.sqrt(3)/2],[-1/2,0.0,math.sqrt(3)/2]), device=device)\n",
    "        # 得到雷达视线方向\n",
    "        Round_radar_los_all = torch.zeros((batch*RadarLos.shape[0],3),device=device)\n",
    "        Round_radar_los_real_all = torch.zeros((batch*RadarLos.shape[0],3),device=device)\n",
    "        omega_vec_all = torch.zeros((batch*omega_vec.shape[0],3),device=device)\n",
    "        for i,j in zip(range(RadarLos.shape[0]),range(omega_vec.shape[0])):\n",
    "                Round_radar_los = vec_rot(RadarLos[i],omega_vec[j,0],omega_vec[j,1],omega_vec[j,2],-theta)\n",
    "                Round_radar_los_all[batch*i:batch*(i+1)] = Round_radar_los\n",
    "                Round_radar_los_real_all[batch*i:batch*(i+1)] = vec_rot(RadarLos[i],omega_vec[j,0],omega_vec[j,1],omega_vec[j,2],theta)\n",
    "                omega_vec_all[batch*j:batch*(j+1)] = omega_vec[j].expand(batch,3)\n",
    "        # 转速\n",
    "        omega = torch.tensor([1.0],device=device).expand(Round_radar_los_all.shape[0])\n",
    "    if modelselect == 5:\n",
    "        # 真实小行星旋转轴轨迹\n",
    "        # batchsi\n",
    "        batch = 37\n",
    "        Round_radar_los_all = torch.zeros((batch,3),device=device)\n",
    "        Round_radar_los_real_all = torch.zeros((batch,3),device=device)\n",
    "        for i in range(batch):\n",
    "            # 雷达视线为螺旋线\n",
    "            RadarLos = torch.tensor([math.sin(-2*math.pi*i/batch/2),(i-batch/2)/batch/30,math.cos(-2*math.pi*i/batch/2)], device=device)\n",
    "            # RadarLos = torch.tensor([0,(i-batch/2)/batch/30,-1], device=device)\n",
    "            RadarLos = RadarLos / (torch.linalg.norm(RadarLos) + 1e-6)\n",
    "            Round_radar_los_all[i] = RadarLos\n",
    "            RadarLos_real = torch.tensor([math.sin(2*math.pi*i/batch/2),(i-batch/2)/batch/30,math.cos(2*math.pi*i/batch/2)], device=device)\n",
    "            RadarLos_real = RadarLos_real / (torch.linalg.norm(RadarLos_real) + 1e-6)\n",
    "            Round_radar_los_real_all[i] = RadarLos_real\n",
    "        omega_vec = torch.tensor(([0.0,1.0,0.0]), device=device)\n",
    "        omega_vec_all = omega_vec.expand(batch,3)\n",
    "        omega = torch.tensor([1.0],device=device).expand(Round_radar_los_all.shape[0])\n",
    "    if modelselect == 6:\n",
    "        # 生成多轨观测小行星的雷达视线方向，仿真得到小行星的nerf模型\n",
    "        # batchsize\n",
    "        batch = 30\n",
    "        # 共生成五轨小行星观测\n",
    "        Round_radar_los_all = torch.zeros((batch*5,3),device=device)\n",
    "        Round_radar_los_real_all = torch.zeros((batch*5,3),device=device)\n",
    "        for j in range(5):\n",
    "            for i in range(batch):\n",
    "                RadarLos = torch.tensor([math.sin(2*math.pi*i/batch),math.tan((j-2)*math.pi/6),math.cos(2*math.pi*i/batch)], device=device)\n",
    "                # RadarLos = torch.tensor([0,(i-batch/2)/batch/30,-1], device=device)\n",
    "                RadarLos = RadarLos / (torch.linalg.norm(RadarLos) + 1e-6)\n",
    "                Round_radar_los_all[i + j*30] = RadarLos\n",
    "                RadarLos_real = torch.tensor([-math.sin(2*math.pi*i/batch),math.tan((j-2)*math.pi/6),math.cos(2*math.pi*i/batch)], device=device)\n",
    "                RadarLos_real = RadarLos_real / (torch.linalg.norm(RadarLos_real) + 1e-6)\n",
    "                Round_radar_los_real_all[i + j*30] = RadarLos_real\n",
    "        omega_vec = torch.tensor(([0.0,1.0,0.0]), device=device)\n",
    "        omega_vec_all = omega_vec.expand(batch*5,3)\n",
    "        omega = torch.tensor([1.0],device=device).expand(Round_radar_los_all.shape[0])\n",
    "    if modelselect == 7:\n",
    "        # 生成多轨观测小行星的雷达视线方向，仿真得到小行星的nerf模型\n",
    "        # batchsize\n",
    "        batch = 30\n",
    "        # 基线数目\n",
    "        baseline_num = 11\n",
    "        # 共生成五轨小行星观测\n",
    "        Round_radar_los_all = torch.zeros((batch*baseline_num,3),device=device)\n",
    "        Round_radar_los_real_all = torch.zeros((batch*baseline_num,3),device=device)\n",
    "        for j in range(baseline_num):\n",
    "            for i in range(batch):\n",
    "                RadarLos = torch.tensor([math.sin(2*math.pi*i/batch),math.tan((j-baseline_num/2)*math.pi/12),math.cos(2*math.pi*i/batch)], device=device)\n",
    "                # RadarLos = torch.tensor([0,(i-batch/2)/batch/30,-1], device=device)\n",
    "                RadarLos = RadarLos / (torch.linalg.norm(RadarLos) + 1e-6)\n",
    "                Round_radar_los_all[i + j*30] = RadarLos\n",
    "                RadarLos_real = torch.tensor([-math.sin(2*math.pi*i/batch),math.tan((j-baseline_num/2)*math.pi/36),math.cos(2*math.pi*i/batch)], device=device)\n",
    "                RadarLos_real = RadarLos_real / (torch.linalg.norm(RadarLos_real) + 1e-6)\n",
    "                Round_radar_los_real_all[i + j*30] = RadarLos_real\n",
    "        omega_vec = torch.tensor(([0.0,1.0,0.0]), device=device)\n",
    "        omega_vec_all = omega_vec.expand(batch*baseline_num,3)\n",
    "        omega = torch.tensor([1.0],device=device).expand(Round_radar_los_all.shape[0])\n",
    "    if modelselect == 8:\n",
    "        # 生成多轨观测小行星的雷达视线方向，仿真得到小行星的nerf模型\n",
    "        # batchsize\n",
    "        batch = 60\n",
    "        # 共生成五轨小行星观测\n",
    "        Round_radar_los_all = torch.zeros((batch,3),device=device)\n",
    "        Round_radar_los_real_all = torch.zeros((batch,3),device=device)\n",
    "        for i in range(batch):\n",
    "            RadarLos = torch.tensor([math.sin(2*math.pi*i/batch+math.pi/2+math.pi),math.tan(40*math.pi/180),math.cos(2*math.pi*i/batch+math.pi/2+math.pi)], device=device)\n",
    "            # RadarLos = torch.tensor([0,(i-batch/2)/batch/30,-1], device=device)\n",
    "            RadarLos = RadarLos / (torch.linalg.norm(RadarLos) + 1e-6)\n",
    "            Round_radar_los_all[i] = RadarLos\n",
    "            RadarLos_real = torch.tensor([-math.sin(2*math.pi*i/batch+math.pi/2+math.pi),math.tan(40*math.pi/180),math.cos(2*math.pi*i/batch+math.pi/2+math.pi)], device=device)\n",
    "            RadarLos_real = RadarLos_real / (torch.linalg.norm(RadarLos_real) + 1e-6)\n",
    "            Round_radar_los_real_all[i] = RadarLos_real\n",
    "        omega_vec = torch.tensor(([0.0,1.0,0.0]), device=device)\n",
    "        omega_vec_all = omega_vec.expand(batch,3)\n",
    "        omega = torch.tensor([1.0],device=device).expand(Round_radar_los_all.shape[0])\n",
    "    # 可视化雷达视线方向\n",
    "    radar_los_numpy = Round_radar_los_all.detach().cpu().numpy()\n",
    "\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=radar_los_numpy[:,0], \n",
    "        y=radar_los_numpy[:,1], \n",
    "        z=radar_los_numpy[:,2], \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2  # 设置点的大小\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    # 可视化转轴方向为一个向量，并将其添加到雷达视线方向图中\n",
    "    omega_vec_numpy = omega_vec_all.detach().cpu().numpy()\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[0, omega_vec_numpy[5,0]],\n",
    "        y=[0, omega_vec_numpy[5,1]],\n",
    "        z=[0, omega_vec_numpy[5,2]],\n",
    "        mode='lines+markers',\n",
    "        marker=dict(size=2),\n",
    "        line=dict(width=2)\n",
    "    ))\n",
    "\n",
    "    # 在中心处添加模型\n",
    "    verts = src_mesh.verts_packed()\n",
    "    verts_numpy = verts.detach().cpu().numpy()\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=verts_numpy[:,0]*0.3, \n",
    "        y=verts_numpy[:,1]*0.3, \n",
    "        z=verts_numpy[:,2]*0.3, \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2  # 设置点的大小\n",
    "        )\n",
    "    ))\n",
    "\n",
    "\n",
    "    # 更新布局\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title='X label',\n",
    "        yaxis_title='Y label',\n",
    "        zaxis_title='Z label'\n",
    "    ))\n",
    "\n",
    "    # 显示图形\n",
    "    fig.show()\n",
    "\n",
    "    # 将图形保存为html文件\n",
    "    fig.write_html(\"Radar_los.html\")\n",
    "\n",
    "    return Round_radar_los_all,Round_radar_los_real_all,omega_vec_all,omega\n",
    "\n",
    "Round_radar_los_all,Round_radar_los_real_all,omega_vec_all,omega = Radarview_generate()\n",
    "print(Round_radar_los_all.shape)\n",
    "print(Round_radar_los_real_all.shape)\n",
    "print(omega_vec_all.shape)\n",
    "print(omega_vec_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对模型进行occlusion culling\n",
    "image = torch.zeros((Round_radar_los_real_all.shape[0],100,100),device=device)\n",
    "image_phase = torch.zeros((Round_radar_los_real_all.shape[0],100,100),device=device)\n",
    "# 雷达视线方向与转轴的夹角\n",
    "theta_los_omega = torch.linalg.cross(Round_radar_los_all,omega_vec_all)\n",
    "# 计算夹角的正弦值\n",
    "sin_theta_los_omega = torch.linalg.norm(theta_los_omega,dim=-1)\n",
    "# 多普勒距离维系数\n",
    "lambda1 = torch.tensor([2.0],device=device)\n",
    "dopplercoefficient = 2*omega/lambda1*sin_theta_los_omega\n",
    "# 实例化occlusion culling和渲染器\n",
    "visible_mesh1 = visible_mesh(device)\n",
    "mesh_radar_render1 = mesh_radar_render(device)\n",
    "# 由于直接进行并行运算显卡内存不够，因此分批次进行\n",
    "plot_pointclouds_rotation(trg_mesh, \"Source mesh\")\n",
    "# for i in range(0,Round_radar_los_real_all.shape[0],50):\n",
    "step = 30\n",
    "loop_num = 2\n",
    "print(\"Shape of Round_radar_los_all[i:i+step]:\", Round_radar_los_all[0:0+step].shape)\n",
    "\n",
    "# 检查 trg_mesh 的形状\n",
    "# print(\"Shape of trg_mesh:\", trg_mesh.shape)\n",
    "for i in range(0,loop_num*step,step):\n",
    "    Meshes_new = visible_mesh1(trg_mesh,Round_radar_los_all[i:i+step])\n",
    "    # plot_pointclouds_rotation(Meshes_new[0], \"occlusion mesh\")\n",
    "    image[i:i+step,:,:]= mesh_radar_render1(Meshes_new,Round_radar_los_all[i:i+step],omega_vec_all[i:i+step],omega[i:i+step],dopplercoefficient[i:i+step])\n",
    "\n",
    "\n",
    "image = torch.rot90(image,k=1,dims=(1,2))\n",
    "image_phase = torch.rot90(image_phase,k=1,dims=(1,2))\n",
    "# 显示成像后的图片\n",
    "plt.figure()\n",
    "plt.imshow(image[0,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "# # # 将图片不带坐标轴的保存\n",
    "# # plt.axis('off')\n",
    "# # plt.savefig('image1.png',bbox_inches='tight',pad_inches=0)\n",
    "# # plt.close()\n",
    "plt.figure()\n",
    "plt.imshow(image[3,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image[6,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image[9,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image[12,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "# plt.imshow(image[15,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "# plt.figure()\n",
    "# plt.imshow(image[6,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "# plt.figure()\n",
    "# plt.imshow(image[9,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "# plt.figure()\n",
    "# plt.imshow(image[12,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "# plt.figure()\n",
    "# plt.imshow(image[60,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "\n",
    "# 显示成像后图片的相位\n",
    "# plt.figure()\n",
    "# plt.imshow(image_phase[0,:,:].squeeze(0).detach().cpu(),cmap='hot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对成像后的图片增加噪声，噪声信噪比分别为-5dB,0dB,5dB,10dB,15dB,20dB\n",
    "# 生成噪声\n",
    "noise = torch.randn_like(image)\n",
    "# 计算图片功率\n",
    "power = torch.sum(image**2)/image.numel()\n",
    "image_power = torch.max(image)\n",
    "print(\"Power of image:\", power)\n",
    "# 信噪比\n",
    "SNR = torch.tensor([5],device=device)\n",
    "# 信噪比对应的噪声方差\n",
    "sigma = torch.sqrt(image_power/(10**(SNR/10)))\n",
    "print(\"Sigma:\", sigma**2)\n",
    "# 生成噪声\n",
    "noise = noise * sigma.view(-1,1,1)\n",
    "# 添加噪声\n",
    "image_new = image\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image_new[3,:,:].squeeze(0).detach().cpu(),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将图片转换为numpy,并保存为png文件\n",
    "image_max = image_new.max().detach().cpu().numpy()\n",
    "# print(image_max)\n",
    "image_min = image_new.min().detach().cpu().numpy()\n",
    "\n",
    "# 存储生成的图片\n",
    "import cv2\n",
    "import numpy as np\n",
    "filename = '/DATA/disk1/asteroid/asteroid_inverse/Instant-ngp/new_dataset/sys_data/tou40du_right'\n",
    "if not os.path.exists(filename):\n",
    "    print(\"创建文件夹\")\n",
    "    os.makedirs(filename)\n",
    "print(Round_radar_los_real_all.shape)\n",
    "for i in range(0,Round_radar_los_real_all.shape[0]):\n",
    "    image_i = image_new[i,:,:].squeeze(0).detach().cpu().numpy()\n",
    "    image_i = (image_i - image_min)/(image_max-image_min)\n",
    "    LOS_real = Round_radar_los_real_all[i].detach().cpu().numpy()\n",
    "    rotation_axis = omega_vec_all[i].detach().cpu().numpy()\n",
    "    print(image_i.max())\n",
    "    print(image_i.min())\n",
    "    np.savez(filename+'/image'+str(i)+\".npz\", image=image_i, LOS = LOS_real, rotation_axis = rotation_axis)\n",
    "    image_i = np.uint8(image_i*255)\n",
    "    cv2.imwrite(filename+'/image'+str(i)+\".png\",image_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
