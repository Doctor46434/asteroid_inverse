{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加库函数\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "from pytorch3d.utils import ico_sphere\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pytorch3d.renderer import (\n",
    "    FoVPerspectiveCameras, look_at_view_transform, look_at_rotation, \n",
    "    RasterizationSettings, MeshRenderer, MeshRasterizer, BlendParams,\n",
    "    SoftSilhouetteShader, HardPhongShader, PointLights, TexturesVertex,OrthographicCameras\n",
    ")\n",
    "from pytorch3d.vis.plotly_vis import plot_batch_individually\n",
    "from pytorch3d.ops.points_normals import estimate_pointcloud_normals\n",
    "from pytorch3d.ops.mesh_face_areas_normals import mesh_face_areas_normals\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_pointcloud(mesh, title=\"\"):\n",
    "    # Sample points uniformly from the surface of the mesh.\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter3D(x, z, -y)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(90, 90)\n",
    "    ax.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "def plot_pointclouds_rotation(mesh, title = \"\"):\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    # 创建 3D 图形\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        z=z, \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2  # 设置点的大小\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    # 更新布局\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title='X轴',\n",
    "        yaxis_title='Y轴',\n",
    "        zaxis_title='Z轴'\n",
    "    ))\n",
    "\n",
    "    # 显示图形\n",
    "    fig.show()\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# Set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:3\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: CPU only, this will be slow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入一个模型\n",
    "trg_obj = 'Geographos Radar-based, low-res(1).obj'\n",
    "# trg_obj = 'wx_origin.obj'\n",
    "\n",
    "# trg_obj = 'dolphin.obj'\n",
    "# 读取卫星各项参数\n",
    "# We read the target 3D model using load_obj\n",
    "verts, faces, aux = load_obj(trg_obj)\n",
    "\n",
    "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "# For this tutorial, normals and textures are ignored.\n",
    "faces_idx = faces.verts_idx.to(device)\n",
    "verts = verts.to(device)\n",
    "\n",
    "# We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "# (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "# Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "center = verts.mean(0)\n",
    "verts = verts - center\n",
    "scale = max(verts.abs().max(0)[0])\n",
    "verts = verts / scale\n",
    "\n",
    "# We construct a Meshes structure for the target mesh\n",
    "trg_mesh = Meshes(verts=[verts], faces=[faces_idx])\n",
    "\n",
    "\n",
    "# 为mesh添加材质信息\n",
    "verts_rgb = torch.ones_like(trg_mesh.verts_packed())*255  # 使用纯白色作为默认颜色\n",
    "verts_rgb = verts_rgb.unsqueeze(0)\n",
    "textures = TexturesVertex(verts_features=verts_rgb)\n",
    "trg_mesh.textures = textures\n",
    "src_mesh = trg_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入初始模型方式\n",
    "# 选择一种载入初始模型的方法\n",
    "flag = 2\n",
    "if flag == 0:\n",
    "    # 载入一个已有的Mesh模型\n",
    "    trg_obj = './ImageGen/3dmodel/Geographos Radar-based, low-res(1).obj'\n",
    "    # trg_obj = 'dolphin.obj'\n",
    "    # trg_obj = 'wx_origin.obj'\n",
    "    # 读取卫星各项参数\n",
    "    # We read the target 3D model using load_obj\n",
    "    verts, faces, aux = load_obj(trg_obj)\n",
    "\n",
    "    # verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "    # faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "    # For this tutorial, normals and textures are ignored.\n",
    "    faces_idx = faces.verts_idx.to(device)\n",
    "    verts = verts.to(device)\n",
    "\n",
    "    # We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "    # (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "    # Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "    center = verts.mean(0)\n",
    "    verts = verts - center\n",
    "    scale = max(verts.abs().max(0)[0])\n",
    "    verts = verts / scale *10\n",
    "\n",
    "    # We construct a Meshes structure for the target mesh\n",
    "    trg_mesh = Meshes(verts=[verts], faces=[faces_idx])\n",
    "\n",
    "\n",
    "    # 为mesh添加材质信息\n",
    "    verts_rgb = torch.ones_like(trg_mesh.verts_packed())*255  # 使用纯白色作为默认颜色\n",
    "    verts_rgb = verts_rgb.unsqueeze(0)\n",
    "    textures = TexturesVertex(verts_features=verts_rgb)\n",
    "    trg_mesh.textures = textures\n",
    "\n",
    "    src_mesh = trg_mesh\n",
    "if flag == 1:\n",
    "    # 载入双球模型\n",
    "\n",
    "    # 创建初始模，两个球体\n",
    "    sphere1 = ico_sphere(4, device)\n",
    "    sphere2 = ico_sphere(4, device)\n",
    "\n",
    "    # 将第一个球体放大到1.5倍\n",
    "    vert1 = sphere2.verts_packed()\n",
    "    vert1 = vert1 * 1.5\n",
    "    sphere2 = Meshes(verts=[vert1], faces=[sphere2.faces_packed()])\n",
    "\n",
    "    # 计算放大后的球体的最大x坐标\n",
    "    max_x1 = sphere1.verts_packed()[:, 0].max()\n",
    "    # 计算第二个球体的最小x坐标\n",
    "    min_x2 = sphere2.verts_packed()[:, 0].min()\n",
    "\n",
    "    # 计算平移量，确保两球体有适当重叠\n",
    "    overlap = 0.1\n",
    "    shift = max_x1 - min_x2 + overlap\n",
    "\n",
    "    # 获取第二个球体的顶点并进行x方向平移\n",
    "    verts2 = sphere2.verts_packed() + torch.tensor([shift, 0, 0], device=device)\n",
    "\n",
    "    # 获取第一个球体的顶点（已经放大）\n",
    "    verts1 = sphere1.verts_packed()\n",
    "\n",
    "    # 合并两球体的顶点\n",
    "    verts = torch.cat([verts1, verts2], dim=0)\n",
    "\n",
    "    # 可以额外添加整体平移\n",
    "    verts = verts + torch.tensor([-1.5, 0, 0], device=device)\n",
    "\n",
    "    # 整体放缩\n",
    "    verts = verts * 0.3\n",
    "\n",
    "    # 合并面片，并更新第二个球体的面片索引\n",
    "    faces1 = sphere1.faces_packed()\n",
    "    faces2 = sphere2.faces_packed() + sphere1.verts_packed().shape[0]  # 更新索引\n",
    "\n",
    "    # 合并面片数据\n",
    "    faces = torch.cat([faces1, faces2], dim=0)\n",
    "\n",
    "    # 创建黏连的球体网格\n",
    "    src_mesh = Meshes(verts=[verts], faces=[faces])\n",
    "\n",
    "if flag == 2:\n",
    "    def create_ellipsoid(level, device, scale_factors=(1.5, 1.0, 0.7)):\n",
    "        \"\"\"\n",
    "        创建椭球体\n",
    "        \n",
    "        参数:\n",
    "            level: ico_sphere 的细分级别\n",
    "            device: 计算设备\n",
    "            scale_factors: (x, y, z) 缩放因子\n",
    "        \"\"\"\n",
    "        # 创建基础球体\n",
    "        sphere = ico_sphere(level, device)\n",
    "        \n",
    "        # 获取球体的顶点和面\n",
    "        verts = sphere.verts_packed()\n",
    "        faces = sphere.faces_packed()\n",
    "        \n",
    "        # 对顶点进行缩放以形成椭球体\n",
    "        x_scale, y_scale, z_scale = scale_factors\n",
    "        scaled_verts = verts.clone()\n",
    "        scaled_verts[:, 0] *= x_scale  # x方向缩放\n",
    "        scaled_verts[:, 1] *= y_scale  # y方向缩放\n",
    "        scaled_verts[:, 2] *= z_scale  # z方向缩放\n",
    "        \n",
    "        # 创建新的网格\n",
    "        ellipsoid = Meshes(verts=[scaled_verts], faces=[faces])\n",
    "        \n",
    "        return ellipsoid\n",
    "    \n",
    "    sphere1 = create_ellipsoid(4, device, scale_factors=(2.0, 1.0, 1.0))\n",
    "    vert = sphere1.verts_packed()\n",
    "    vert = vert * 0.5\n",
    "\n",
    "    src_mesh = Meshes(verts=[vert], faces=[sphere1.faces_packed()])\n",
    "\n",
    "trg_mesh = src_mesh\n",
    "# 绘制初始情况下的src_mesh\n",
    "plot_pointcloud(src_mesh, \"Source mesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建一个球\n",
    "# trg_mesh = ico_sphere(4, device)\n",
    "# verts = trg_mesh.verts_packed()\n",
    "# faces = trg_mesh.faces_packed()\n",
    "# scaled_verts = verts * 0.5\n",
    "\n",
    "# # 将两球质点平移\n",
    "# scaled_verts = scaled_verts + torch.tensor([0, 0, 0.4], device=device)\n",
    "\n",
    "# trg_mesh = Meshes(verts=[scaled_verts], faces=[faces])\n",
    "\n",
    "# # 绘制初始情况下的src_mesh\n",
    "# plot_pointcloud(trg_mesh, \"Source mesh\")\n",
    "# 创建一个球\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trg_mesh.faces_packed().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入大小为[1,3]初始向量vec，大小分别为[1]旋转轴axis_x,axis_y,axis_z，大小为[num,1]的旋转角度theta，输出大小为[num,3]的旋转后向量\n",
    "def vec_rot(vec,axis_x,axis_y,axis_z,theta):\n",
    "\n",
    "    axis_x = axis_x.expand(theta.shape)\n",
    "    axis_y = axis_y.expand(theta.shape)\n",
    "    axis_z = axis_z.expand(theta.shape)\n",
    "\n",
    "    c = torch.cos(theta)\n",
    "    s = torch.sin(theta)\n",
    "    one_c = 1 - c\n",
    "\n",
    "    Rotmat = torch.stack([\n",
    "        torch.stack([axis_x**2 * one_c + c, axis_x * axis_y * one_c - axis_z * s, axis_x * axis_z * one_c + axis_y * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_y * one_c + axis_z * s, axis_y**2 * one_c + c, axis_y * axis_z * one_c - axis_x * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_z * one_c - axis_y * s, axis_y * axis_z * one_c + axis_x * s, axis_z**2 * one_c + c], dim=-1)\n",
    "    ], dim=-2)\n",
    "\n",
    "    vec_rot = torch.matmul(Rotmat,vec.unsqueeze(1)).squeeze(2)\n",
    "\n",
    "    return vec_rot\n",
    "\n",
    "# batchsize\n",
    "batch = 60\n",
    "# 雷达视线方向1\n",
    "RadarLos = torch.tensor([0,math.sin(40*math.pi/180),math.cos(40*math.pi/180),], device=device)\n",
    "theta = torch.linspace(2*math.pi,2*math.pi/batch,batch).to(device)\n",
    "\n",
    "axis_x = torch.tensor([0.0], device=device)\n",
    "axis_y = torch.tensor([1.0], device=device)\n",
    "axis_z = torch.tensor([0.0], device=device)\n",
    "\n",
    "# # 雷达视线方向2\n",
    "# RadarLos = torch.tensor([0,math.sqrt(3)/2,-1/2], device=device)\n",
    "# theta = torch.linspace(0,2*math.pi,batch).to(device)\n",
    "\n",
    "# axis_x = torch.tensor([0.0], device=device)\n",
    "# axis_y = torch.tensor([1.0], device=device)\n",
    "# axis_z = torch.tensor([0.0], device=device)\n",
    "\n",
    "# Round_radar_los = vec_rot(RadarLos,axis_x,axis_y,axis_z,-theta)\n",
    "\n",
    "# # 雷达视线方向3\n",
    "# RadarLos = torch.tensor([0,-math.sqrt(3)/2,-1/2], device=device)\n",
    "# theta = torch.linspace(0,2*math.pi,batch).to(device)\n",
    "\n",
    "# axis_x = torch.tensor([0.0], device=device)\n",
    "# axis_y = torch.tensor([1.0], device=device)\n",
    "# axis_z = torch.tensor([0.0], device=device)\n",
    "\n",
    "# # 雷达视线方向4\n",
    "# RadarLos = torch.tensor([0,0,-1.0], device=device)\n",
    "# theta = torch.linspace(0,2*math.pi,batch).to(device)\n",
    "\n",
    "# axis_x = torch.tensor([0.0], device=device)\n",
    "# axis_y = torch.tensor([math.sqrt(3)/2], device=device)\n",
    "# axis_z = torch.tensor([1/2], device=device)\n",
    "\n",
    "# # 雷达视线方向5\n",
    "# RadarLos = torch.tensor([0,0,-1.0], device=device)\n",
    "# theta = torch.linspace(0,2*math.pi,batch).to(device)\n",
    "\n",
    "# axis_x = torch.tensor([0.0], device=device)\n",
    "# axis_y = torch.tensor([math.sqrt(3)/2], device=device)\n",
    "# axis_z = torch.tensor([-1/2], device=device)\n",
    "\n",
    "Round_radar_los = vec_rot(RadarLos,axis_x,axis_y,axis_z,-theta)\n",
    "Round_radar_los_real = vec_rot(RadarLos,axis_x,axis_y,axis_z,theta)\n",
    "\n",
    "# # 打印雷达视线方向\n",
    "# 可视化雷达视线方向\n",
    "# radar_los_numpy = Round_radar_los.detach().cpu().numpy()\n",
    "\n",
    "# fig = go.Figure(data=[go.Scatter3d(\n",
    "#     x=radar_los_numpy[:,0], \n",
    "#     y=radar_los_numpy[:,1], \n",
    "#     z=radar_los_numpy[:,2], \n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=2  # 设置点的大小\n",
    "#     )\n",
    "# )])\n",
    "\n",
    "# # 更新布局\n",
    "# fig.update_layout(scene=dict(\n",
    "#     xaxis_title='X轴',\n",
    "#     yaxis_title='Y轴',\n",
    "#     zaxis_title='Z轴'\n",
    "# ))\n",
    "\n",
    "# # 显示图形\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制造可视化模型\n",
    "class visible_mesh(nn.Module):\n",
    "    def __init__(self,device) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,mesh,RadarLos):\n",
    "        batch = RadarLos.shape[0]\n",
    "        face_num = mesh.faces_packed().shape[0]\n",
    "        face_mask = torch.zeros((batch,face_num),dtype=bool,device=self.device)\n",
    "        # 计算由函数look_at_view_transform得到的旋转矩阵和平移矩阵\n",
    "        at = torch.tensor([0.0, 0.0, 0.0], device=device).expand(RadarLos.shape)\n",
    "        up = torch.tensor([0.0, 1.0, 0.0], device=device).expand(RadarLos.shape)\n",
    "\n",
    "        R, T = look_at_view_transform(eye=RadarLos*3, at=at, up=up)\n",
    "        # 生成渲染器\n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=1024, \n",
    "            blur_radius=0.0, \n",
    "            faces_per_pixel=1, \n",
    "        )\n",
    "        # 生成相机\n",
    "        cameras = OrthographicCameras(device=self.device, R=R, T=T)\n",
    "        # 生成栅格化器\n",
    "        rasterizer = MeshRasterizer(\n",
    "            cameras=cameras,\n",
    "            raster_settings=raster_settings\n",
    "        )\n",
    "        fragments = rasterizer(mesh.extend(batch))\n",
    "        # 在并行处理时，一个batch中的不同mesh有不同的面标识，但这些面标识有规律的从小到大排列,因此可以直接Unique\n",
    "        p2f = fragments.pix_to_face\n",
    "        p2f_mask = p2f[p2f>=0]\n",
    "        p2f_mask_unique = torch.unique(p2f_mask)\n",
    "        face_mask = face_mask.view(-1)\n",
    "        face_mask[p2f_mask_unique] = True\n",
    "        face_mask = face_mask.view(batch,-1)\n",
    "\n",
    "        all_faces = mesh.faces_packed()\n",
    "        all_verts = mesh.verts_packed() \n",
    "        # 利用面掩码生成批次索引\n",
    "        batch_size, num_faces = face_mask.shape\n",
    "        faces_batch = [all_faces[m] for m in face_mask]\n",
    "        verts_batch = [all_verts] * batch_size  # 假设每个 batch 使用同样的顶点\n",
    "        # 直接创建 Meshes 对象\n",
    "        Meshes_new = Meshes(verts=verts_batch, faces=faces_batch)\n",
    "\n",
    "\n",
    "        return Meshes_new\n",
    "    \n",
    "\n",
    "visible_mesh1 = visible_mesh(device)\n",
    "Meshes_new = visible_mesh1(trg_mesh,Round_radar_los[0:20])\n",
    "print(Meshes_new.verts_packed().shape)\n",
    "\n",
    "\n",
    "# faces = trg_mesh.faces_packed()[face_mask[6,:]]\n",
    "# verts = trg_mesh.verts_packed()\n",
    "\n",
    "# Meshes_new = Meshes(verts=[verts], faces=[faces])\n",
    "\n",
    "\n",
    "\n",
    "# plot_pointclouds_rotation(Meshes_new[7])\n",
    "# plot_pointclouds_rotation(Meshes_new[9])\n",
    "# plot_pointclouds_rotation(Meshes_new[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得相机位置和视线位置对应的旋转矩阵\n",
    "\n",
    "def get_normals(meshes):\n",
    "    verts_packed = meshes.verts_packed()  # (V, 3)\n",
    "    faces_packed = meshes.faces_packed()  # (F, 3)\n",
    "\n",
    "    # 获取每个面的顶点\n",
    "    faces_verts = verts_packed[faces_packed]  # (F, 3, 3)\n",
    "\n",
    "    # 计算叉乘，获取法向量\n",
    "    face_normals = torch.cross(\n",
    "        faces_verts[:, 1] - faces_verts[:, 0],\n",
    "        faces_verts[:, 2] - faces_verts[:, 0],\n",
    "        dim=1\n",
    "    )\n",
    "\n",
    "    # 归一化法向量\n",
    "    face_normals = face_normals / (face_normals.norm(dim=1, keepdim=True) + 1e-6)\n",
    "\n",
    "    # face_normals 现在是每个面的法向量\n",
    "    return face_normals\n",
    "\n",
    "def rr2rd(meshes, doppler_vec, dopplercoefficient):\n",
    "    verts_list = meshes.verts_list()\n",
    "    faces_list = meshes.faces_list()\n",
    "    # 将dopplercorfficient转换为list\n",
    "    dopplercoefficient = dopplercoefficient.tolist()\n",
    "\n",
    "    # 确保 doppler_vec 的长度等于 verts_list 的长度\n",
    "    if len(doppler_vec) != len(verts_list):\n",
    "        raise ValueError(\"Length of doppler_vec must match number of vertex lists\")\n",
    "    # print(doppler_vec)\n",
    "    # print(verts_list.shape)\n",
    "    projection_list = [\n",
    "        (verts @ doppler_vec[i].unsqueeze(1)) * doppler_vec[i].unsqueeze(1).T\n",
    "        for i, verts in enumerate(verts_list)\n",
    "    ]\n",
    "    \n",
    "    scaled_projection = [proj * coefficient for proj,coefficient in zip(projection_list,dopplercoefficient)]\n",
    "    scaled_verts_list = [verts + (scaled - proj) for verts, scaled, proj in zip(verts_list, scaled_projection, projection_list)]\n",
    "\n",
    "    # 创建新的 Meshes 对象\n",
    "    meshes_scaled = Meshes(verts=scaled_verts_list, faces=faces_list)\n",
    "\n",
    "    return meshes_scaled\n",
    "\n",
    "def angel2vec(ele,azi):\n",
    "    elev_rad = torch.deg2rad(ele)\n",
    "    azim_rad = torch.deg2rad(azi)\n",
    "    \n",
    "    direction_vector = torch.stack([\n",
    "        torch.cos(elev_rad) * torch.sin(azim_rad),\n",
    "        torch.sin(elev_rad),\n",
    "        torch.cos(elev_rad) * torch.cos(azim_rad)\n",
    "    ],dim=-1)\n",
    "\n",
    "    return direction_vector\n",
    "\n",
    "class mesh_radar_render(nn.Module):\n",
    "    def __init__(self,device) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self,meshes,radarlos,omega_vec,omega,dopplercoefficient):\n",
    "\n",
    "        # 输入为 mesh [batch]\n",
    "        # radarele [batch]\n",
    "        # radarazi [batch]\n",
    "        # omegaele [batch]\n",
    "        # omegaazi [batch]\n",
    "        # omega [batch]\n",
    "\n",
    "        # from opts import config_parser\n",
    "        # parser = config_parser()\n",
    "        # args = parser.parse_args()\n",
    "\n",
    "\n",
    "        # 多普勒轴\n",
    "        doppler_vec = torch.linalg.cross(radarlos,omega_vec)\n",
    "        # 对doppler_vec进行归一化\n",
    "        doppler_vec = doppler_vec / (torch.linalg.norm(doppler_vec,dim=-1).unsqueeze(-1) + 1e-6)\n",
    "        # print(radarlos[0])\n",
    "        # print(omega_vec[0])\n",
    "        # print(doppler_vec[0])\n",
    "        # 生成成像方向\n",
    "        image_vec = torch.linalg.cross(radarlos,doppler_vec)\n",
    "        # print(image_vec.shape)\n",
    "        # print(image_vec)\n",
    "        # 将Image——vec向量可视化\n",
    "        image_vec_numpy = image_vec.detach().cpu().numpy()\n",
    "        # for i in range(image_vec_numpy.shape[0]):\n",
    "        #     fig.add_trace(go.Scatter3d(\n",
    "        #         x=[0, image_vec_numpy[i,0]],\n",
    "        #         y=[0, image_vec_numpy[i,1]],\n",
    "        #         z=[0, image_vec_numpy[i,2]],\n",
    "        #         mode='lines+markers',\n",
    "        #         marker=dict(size=4),\n",
    "        #         line=dict(width=5)\n",
    "        #     ))\n",
    "        # # 将omega_vec向量可视化\n",
    "        # omega_vec_numpy = omega_vec.detach().cpu().numpy()\n",
    "        # for i in range(omega_vec_numpy.shape[0]):\n",
    "        #     fig.add_trace(go.Scatter3d(\n",
    "        #         x=[0, omega_vec_numpy[i,0]],\n",
    "        #         y=[0, omega_vec_numpy[i,1]],\n",
    "        #         z=[0, omega_vec_numpy[i,2]],\n",
    "        #         mode='lines+markers',\n",
    "        #         marker=dict(size=4),\n",
    "        #         line=dict(width=5)\n",
    "        #     ))\n",
    "        # # 将doppler_vec向量可视化\n",
    "        # doppler_vec_numpy = doppler_vec.detach().cpu().numpy()\n",
    "        # for i in range(doppler_vec_numpy.shape[0]):\n",
    "        #     fig.add_trace(go.Scatter3d(\n",
    "        #         x=[0, doppler_vec_numpy[i,0]],\n",
    "        #         y=[0, doppler_vec_numpy[i,1]],\n",
    "        #         z=[0, doppler_vec_numpy[i,2]],\n",
    "        #         mode='lines+markers',\n",
    "        #         marker=dict(size=4),\n",
    "        #         line=dict(width=5)\n",
    "        #     ))\n",
    "        # # 更新布局\n",
    "        # fig.update_layout(scene=dict(\n",
    "        #     xaxis_title='X轴',\n",
    "        #     yaxis_title='Y轴',\n",
    "        #     zaxis_title='Z轴'\n",
    "        # ))\n",
    "\n",
    "        # # 将坐标轴设置为相等\n",
    "        # fig.update_layout(scene_aspectmode='cube')\n",
    "\n",
    "        # # 显示图形\n",
    "        # fig.show()\n",
    "        # 计算由函数look_at_view_transform得到的旋转矩阵和平移矩阵\n",
    "        at = torch.tensor([0.0, 0.0, 0.0], device=device).expand(radarlos.shape)\n",
    "\n",
    "        R, T = look_at_view_transform(eye=image_vec*3, at=at, up=radarlos)\n",
    "        cameras = OrthographicCameras(device=device, R=R, T=T)\n",
    "        # 获得法向量\n",
    "        normals = get_normals(meshes)\n",
    "        # 对mesh进行变换到多普勒域\n",
    "        meshes_scaled = rr2rd(meshes,doppler_vec,dopplercoefficient)\n",
    "        # 渲染\n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=(100,100), \n",
    "            blur_radius=0, \n",
    "            faces_per_pixel=3,\n",
    "        )\n",
    "        rasterizer=MeshRasterizer(\n",
    "            cameras=cameras, \n",
    "            raster_settings=raster_settings\n",
    "        )\n",
    "        fragments = rasterizer(meshes_scaled)\n",
    "        # print(fragments.pix_to_face.shape)\n",
    "        # print(fragments.pix_to_face[0,50,:,:])\n",
    "        zero_vector = torch.zeros(1, 3, device=self.device)\n",
    "        normal_batch = torch.where(\n",
    "            fragments.pix_to_face[...,None] == -1,                      # 添加维度适配零向量\n",
    "            zero_vector,                               # 用零向量替换不合法的索引\n",
    "            normals[fragments.pix_to_face.clamp_min(0)]                  # 使用 torch.clamp_min 防止负值索引\n",
    "        )\n",
    "        image = torch.sum(normal_batch*radarlos.unsqueeze(1).unsqueeze(2).unsqueeze(3),dim=-1)\n",
    "        # 删除image中的所有负值\n",
    "        image = torch.nn.functional.relu(image)\n",
    "        image = torch.sum(image,dim = -1)\n",
    "\n",
    "        return image\n",
    "\n",
    "def vec_rot(vec,axis_x,axis_y,axis_z,theta):\n",
    "\n",
    "    axis_x = axis_x.expand(theta.shape)\n",
    "    axis_y = axis_y.expand(theta.shape)\n",
    "    axis_z = axis_z.expand(theta.shape)\n",
    "\n",
    "    c = torch.cos(theta)\n",
    "    s = torch.sin(theta)\n",
    "    one_c = 1 - c\n",
    "\n",
    "    Rotmat = torch.stack([\n",
    "        torch.stack([axis_x**2 * one_c + c, axis_x * axis_y * one_c - axis_z * s, axis_x * axis_z * one_c + axis_y * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_y * one_c + axis_z * s, axis_y**2 * one_c + c, axis_y * axis_z * one_c - axis_x * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_z * one_c - axis_y * s, axis_y * axis_z * one_c + axis_x * s, axis_z**2 * one_c + c], dim=-1)\n",
    "    ], dim=-2)\n",
    "\n",
    "    vec_rot = torch.matmul(Rotmat,vec.unsqueeze(1)).squeeze(2)\n",
    "\n",
    "    return vec_rot\n",
    "\n",
    "# print(Round_radar_los.shape)\n",
    "# 转轴\n",
    "omega_vec = torch.tensor([0.0,1.0,0.0],device=device).expand(Round_radar_los.shape)\n",
    "# 转速\n",
    "omega = torch.tensor([1.0],device=device).expand(Round_radar_los.shape[0])\n",
    "# omega = torch.tensor([1],device=device).expand(Round_radar_los.shape[0])\n",
    "# 雷达视线方向与转轴的夹角\n",
    "theta_los_omega = torch.linalg.cross(Round_radar_los,omega_vec)\n",
    "# 计算夹角的正弦值\n",
    "sin_theta_los_omega = torch.linalg.norm(theta_los_omega,dim=-1)\n",
    "# 多普勒距离维系数\n",
    "lambda1 = torch.tensor([2.0],device=device)\n",
    "dopplercoefficient = 2*omega/lambda1*sin_theta_los_omega\n",
    "# dopplercoefficient = torch.tensor([1.0],device=device).expand(Round_radar_los.shape[0])\n",
    "mesh_radar_render1 = mesh_radar_render(device)\n",
    "# # 调用mesh_radar_render1函数进行渲染\n",
    "# print(Meshes_new.verts_packed().shape)\n",
    "# print(Round_radar_los[0:5,:].shape)\n",
    "# print(omega_vec[0:5,:].shape)\n",
    "# print(omega[0:5].shape)\n",
    "# print(dopplercoefficient[0:5].shape)\n",
    "image = mesh_radar_render1(Meshes_new,Round_radar_los[0:20,:],omega_vec[0:20,:],omega[0:20],dopplercoefficient[0:20])     \n",
    "# 添加噪声\n",
    "# noise = torch.rand_like(image)\n",
    "# noise = torch.sqrt(-0.5 * torch.log(noise))\n",
    "# image = image + noise\n",
    "\n",
    "image = torch.rot90(image,k=1,dims=(1,2))\n",
    "plt.figure()\n",
    "plt.imshow(image[0,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image[3,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image[6,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image[9,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image[12,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image[15,:,:].squeeze(0).detach().cpu(),cmap='hot')\n",
    "\n",
    "# # 将图片转换为numpy,并保存为png文件\n",
    "# image_max = image.max().detach().cpu().numpy()\n",
    "# # print(image_max)\n",
    "# image_min = image.min().detach().cpu().numpy()\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# filename = './ISAR_NERF/asteroid_image_nerf_new/task3'\n",
    "# if not os.path.exists(filename):\n",
    "#     print(\"创建文件夹\")\n",
    "#     os.makedirs(filename)\n",
    "# for i in range(0,30):\n",
    "#     image_i = image[i,:,:].squeeze(0).detach().cpu().numpy()\n",
    "#     image_i = (image_i - image_min)/(image_max-image_min)\n",
    "#     LOS_real = Round_radar_los_real[i].detach().cpu().numpy()\n",
    "#     rotation_axis = omega_vec[i].detach().cpu().numpy()\n",
    "\n",
    "#     np.savez(filename+'/image'+str(i+60)+\".npz\", image=image_i, LOS = LOS_real, rotation_axis = rotation_axis)\n",
    "#     image_i = np.uint8(image_i*255)\n",
    "#     cv2.imwrite(filename+'/image'+str(i+60)+\".png\",image_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 自然排序函数\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    # 分割字符串中的数字并将它们转换为整数\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def loaddata(folder_path):\n",
    "    '''\n",
    "    输入文件夹路径，输出数据集\n",
    "    '''\n",
    "    # 获取文件夹中的所有文件和子文件夹\n",
    "    items = os.listdir(folder_path)\n",
    "    # 过滤出所有文件（排除子文件夹）\n",
    "    files = [item for item in items if os.path.isfile(os.path.join(folder_path, item)) and item.endswith('.npz')]\n",
    "    files_sorted = sorted(files, key=natural_sort_key)\n",
    "    #载入数据\n",
    "    images = []\n",
    "    LOS_dirs = []\n",
    "    omegas = []\n",
    "    max_pixel = []\n",
    "    for file in files_sorted:\n",
    "        full_path = folder_path+\"/\"+file\n",
    "        data = np.load(full_path)\n",
    "        image = torch.from_numpy(data['image']).to(device)\n",
    "        LOS_dir = torch.from_numpy(data['LOS']).to(device)\n",
    "        omega = torch.from_numpy(data['rotation_axis']).to(device)\n",
    "        images.append(image)\n",
    "        LOS_dirs.append(LOS_dir)\n",
    "        omegas.append(omega)\n",
    "    max_pixel = [torch.max(image) for image in images]\n",
    "    max_pixel_all = max(max_pixel, key=lambda x: x.item())\n",
    "    images_normalize = [image/max_pixel_all for image in images]\n",
    "    return images_normalize,LOS_dirs,omegas\n",
    "\n",
    "# 输入数据2\n",
    "image_input,_,_ = loaddata('/DATA/disk1/asteroid/asteroid_inverse/Instant-ngp/new_dataset/sys_data/tou_round/30du_40dB')\n",
    "# 将列表转换为torch\n",
    "image_input = torch.stack(image_input, dim=0)\n",
    "image_input = image_input.to(device)\n",
    "print(image_input.shape)\n",
    "image_input = torch.abs(image_input)\n",
    "\n",
    "plt.imshow(image_input[3,:,:].detach().cpu(),cmap='hot')\n",
    "# 数据归一化\n",
    "max_values, _ = torch.max(image_input, dim=2)\n",
    "max_values_dim1, _ = torch.max(max_values, dim=1)\n",
    "image_trg = image_input/max_values_dim1.unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deform_verts = torch.full(trg_mesh.verts_packed().shape, 0.0, device=device, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.Adam([deform_verts], lr=0.005)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=4000,eta_min=1e-3)\n",
    "\n",
    "\n",
    "# Number of optimization steps\n",
    "Niter = 4000\n",
    "# Weight for the image loss\n",
    "w_image = 0.003\n",
    "# Weight for mesh edge loss\n",
    "w_edge = 100\n",
    "# Weight for mesh normal consistency\n",
    "w_normal = 10\n",
    "# Weight for mesh laplacian smoothing\n",
    "w_laplacian = 100\n",
    "# Plot period for the losses\n",
    "plot_period = 250\n",
    "loop = tqdm(range(Niter))\n",
    "\n",
    "image_losses = []\n",
    "laplacian_losses = []\n",
    "edge_losses = []\n",
    "normal_losses = []\n",
    "\n",
    "for i in loop:\n",
    "    # Initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Deform the mesh\n",
    "    new_src_mesh = trg_mesh.offset_verts(deform_verts)\n",
    "    \n",
    "    # 每轮选取三个视角进行训练\n",
    "    random_numbers = np.random.choice(range(0, 30), 6, replace=False)\n",
    "    Meshes_new = visible_mesh1(new_src_mesh,Round_radar_los[random_numbers])\n",
    "    image_src = mesh_radar_render1(Meshes_new,Round_radar_los[random_numbers],omega_vec[random_numbers,:],omega[random_numbers],dopplercoefficient)     \n",
    "    image_src = torch.rot90(image_src,k=1,dims=(1,2))\n",
    "    # 取模归一化\n",
    "    image_src = torch.abs(image_src)\n",
    "    max1,_ = torch.max(image_src,dim=2)\n",
    "    max2,_ = torch.max(max1,dim=1)\n",
    "    image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    image_trg_sample = image_trg[random_numbers,:,:]\n",
    "    \n",
    "    # 计算简单的mse\n",
    "    loss_image = torch.sum((image_trg_sample - image_src)**2)\n",
    "    \n",
    "    # and (b) the edge length of the predicted mesh\n",
    "    loss_edge = mesh_edge_loss(new_src_mesh)\n",
    "    \n",
    "    # mesh normal consistency\n",
    "    loss_normal = mesh_normal_consistency(new_src_mesh)\n",
    "    \n",
    "    # mesh laplacian smoothing\n",
    "    loss_laplacian = mesh_laplacian_smoothing(new_src_mesh, method=\"uniform\")\n",
    "    \n",
    "    # Weighted sum of the losses\n",
    "    loss = loss_image * w_image + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
    "    \n",
    "    # Print the losses\n",
    "    loop.set_description('total_loss = %.6f' % loss)\n",
    "    \n",
    "    # Save the losses for plotting\n",
    "    image_losses.append(float(loss_image.detach().cpu()))\n",
    "    edge_losses.append(float(loss_edge.detach().cpu()))\n",
    "    normal_losses.append(float(loss_normal.detach().cpu()))\n",
    "    laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
    "    \n",
    "    # Plot mesh\n",
    "    if i % plot_period == 0:\n",
    "        plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)\n",
    "        plt.figure()\n",
    "        plt.imshow(image_src[0,:,:].detach().cpu(),cmap='hot')\n",
    "        plt.colorbar()\n",
    "        plt.figure()\n",
    "        plt.imshow(image_trg_sample[0,:,:].detach().cpu(),cmap='hot')\n",
    "        plt.colorbar()\n",
    "        \n",
    "    # Optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_image = loss_image\n",
    "\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "ax = fig.gca()\n",
    "ax.plot([x*w_image for x in image_losses], label=\"image losses\")\n",
    "ax.plot([x*w_edge for x in edge_losses], label=\"edge loss\")\n",
    "ax.plot([x*w_normal for x in normal_losses], label=\"normal loss\")\n",
    "ax.plot([x*w_laplacian for x in laplacian_losses], label=\"laplacian loss\")                                                                                                                                  \n",
    "ax.legend(fontsize=\"16\")\n",
    "ax.set_xlabel(\"Iteration\", fontsize=\"16\")\n",
    "ax.set_ylabel(\"Loss\", fontsize=\"16\")\n",
    "ax.set_title(\"Loss vs iterations\", fontsize=\"16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_individually(new_src_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_image = loss_image\n",
    "\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "ax = fig.gca()\n",
    "ax.plot([x*w_image for x in image_losses], label=\"image losses\")\n",
    "ax.plot([x*w_edge for x in edge_losses], label=\"edge loss\")\n",
    "ax.plot([x*w_normal for x in normal_losses], label=\"normal loss\")\n",
    "ax.plot([x*w_laplacian for x in laplacian_losses], label=\"laplacian loss\")                                                                                                                                  \n",
    "ax.legend(fontsize=\"16\")\n",
    "ax.set_xlabel(\"Iteration\", fontsize=\"16\")\n",
    "ax.set_ylabel(\"Loss\", fontsize=\"16\")\n",
    "ax.set_title(\"Loss vs iterations\", fontsize=\"16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/DATA/disk1/asteroid/asteroid_inverse/Instant-ngp/new_dataset/result/mesh_snr'\n",
    "full_path = filename + '/tou/40db'\n",
    "if not os.path.exists(full_path):\n",
    "    print(\"创建文件夹\")\n",
    "    os.makedirs(full_path)\n",
    "\n",
    "\n",
    "verts = new_src_mesh.verts_packed()\n",
    "faces = new_src_mesh.faces_packed()\n",
    "\n",
    "save_obj(full_path + '/model', verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# mesh_radar_render1 = mesh_radar_render(device)\n",
    "\n",
    "Meshes_new = visible_mesh1(new_src_mesh,Round_radar_los)\n",
    "image_src = mesh_radar_render1(Meshes_new,Round_radar_los,omega_vec,omega,dopplercoefficient)   \n",
    "# 取模归一化\n",
    "image_src = torch.abs(image_src)\n",
    "max1,_ = torch.max(image_src,dim=2)\n",
    "max2,_ = torch.max(max1,dim=1)\n",
    "image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "plt.figure()\n",
    "plt.imshow(image_src[0,:,:].detach().cpu(),cmap='hot')\n",
    "for i in range(30):\n",
    "    Meshes_new = visible_mesh1(new_src_mesh,Round_radar_los[i:i+1])\n",
    "    image_src = mesh_radar_render1(Meshes_new,Round_radar_los[i:i+1],omega_vec[i:i+1,:],omega[i:i+1],dopplercoefficient)     \n",
    "    image_src = torch.abs(image_src)\n",
    "    max1,_ = torch.max(image_src,dim=2)\n",
    "    max2,_ = torch.max(max1,dim=1)\n",
    "    image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "    image_src = torch.rot90(image_src,k=1,dims=(1,2))\n",
    "    # print(image_src.shape)\n",
    "    image_save = image_src[0,:,:].detach().cpu()\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.imshow(image_save,cmap='hot')  \n",
    "\n",
    "    array = image_save.squeeze(0).numpy() * 255  # 转换为数组并缩放到 0-255 范围\n",
    "    array = array.astype('uint8')  # 将类型转换为 8 位整数\n",
    "\n",
    "    # 创建一个 PIL 图片对象\n",
    "    image = Image.fromarray(array, mode='L')  # 'L' 模式表示灰度图像\n",
    "\n",
    "    # 确定保存路径\n",
    "    output_folder = full_path + '/images/'\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    image_name = 'image' + str(i) + '.png'\n",
    "    # os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, image_name)\n",
    "\n",
    "    # print(f\"Saving image to {output_path}\")\n",
    "    # 保存图片\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
