{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加库函数\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import (\n",
    "    chamfer_distance, \n",
    "    mesh_edge_loss, \n",
    "    mesh_laplacian_smoothing, \n",
    "    mesh_normal_consistency,\n",
    ")\n",
    "from pytorch3d.utils import ico_sphere\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pytorch3d.renderer import (\n",
    "    FoVPerspectiveCameras, look_at_view_transform, look_at_rotation, \n",
    "    RasterizationSettings, MeshRenderer, MeshRasterizer, BlendParams,\n",
    "    SoftSilhouetteShader, HardPhongShader, PointLights, TexturesVertex,\n",
    ")\n",
    "from pytorch3d.vis.plotly_vis import plot_batch_individually\n",
    "from pytorch3d.ops.points_normals import estimate_pointcloud_normals\n",
    "from pytorch3d.ops.mesh_face_areas_normals import mesh_face_areas_normals\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "def gaussian_pdf(x, mu, sigma):\n",
    "    const = 1.0\n",
    "    exp = torch.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "    return const * exp\n",
    "\n",
    "class ISAR_render(nn.Module):\n",
    "    def __init__(self, device) -> None:\n",
    "        super().__init__()\n",
    "        self.c = torch.tensor([299792458.0], device=device)\n",
    "        self.Tcoh = torch.tensor([10.0*16], device=device)\n",
    "        self.PRF = torch.tensor([20.0], device=device)\n",
    "        self.fc = torch.tensor([9.7e9], device=device)\n",
    "        self.Tp = torch.tensor([5e-4], device=device)\n",
    "        self.B = torch.tensor([30e7*16], device=device)\n",
    "        self.Range_map,self.Dopple_map = torch.meshgrid(torch.linspace(-10,10,100).to(device),torch.linspace(-3,3,100).to(device), indexing='xy')\n",
    "        self.lambda1 = self.c/self.fc\n",
    "        self.RangeRes = self.c/self.B/2*5\n",
    "        self.complex_i = torch.tensor([1j], dtype=torch.complex64, device=device)\n",
    "\n",
    "    def forward(self, mesh, RadarLos, SpinAxis, Omega):\n",
    "        # 输入\n",
    "        # mesh为pytorch3d自带的结构，采样后采样点为：sampled_points [batchsize,N,3] point_normals [batchsize,N,3]\n",
    "        # 雷达视线方向 RadarLos [batchsize,3]\n",
    "        # 转轴 SpinAxis [batchsize,3]\n",
    "        sampled_points,point_normals = sample_points_from_meshes(mesh, 8000, return_normals=True)\n",
    "        DopplerAxis = torch.cross(RadarLos,SpinAxis,dim = -1)\n",
    "        point_vel = torch.cross(SpinAxis.unsqueeze(1),sampled_points,dim = -1)\n",
    "        point_vel_Radial = Omega * torch.sum(RadarLos.unsqueeze(1)*point_vel,dim=2)\n",
    "        point_doppler = -2*point_vel_Radial/self.lambda1\n",
    "        point_range = torch.sum(RadarLos.unsqueeze(1)*sampled_points,dim=2)\n",
    "        point_Amp = -4*torch.sum(RadarLos.unsqueeze(1)*point_normals, dim=2)\n",
    "        point_Amp = point_Amp\n",
    "        point_Amp = torch.clamp(point_Amp,min=0.0,max=1.0)\n",
    "        DopplerRes = self.lambda1/2/Omega/self.Tcoh\n",
    "\n",
    "        # range_idx = torch.round\n",
    "        \n",
    "        # image_AllPoint = torch.sinc(1/self.RangeRes*(self.Range_map.unsqueeze(0).unsqueeze(1)-point_range.unsqueeze(2).unsqueeze(3))) * torch.sinc(1/DopplerRes*(self.Dopple_map.unsqueeze(0).unsqueeze(1)-point_doppler.unsqueeze(2).unsqueeze(3))) * torch.exp(-4*math.pi*self.complex_i/self.lambda1*point_range.unsqueeze(2).unsqueeze(3))\n",
    "        # image_AllPoint = point_Amp.unsqueeze(2).unsqueeze(3)*torch.sinc(1/self.RangeRes*(self.Range_map.unsqueeze(0).unsqueeze(1)-point_range.unsqueeze(2).unsqueeze(3))) * torch.sinc(1/DopplerRes*(self.Dopple_map.unsqueeze(0).unsqueeze(1)-point_doppler.unsqueeze(2).unsqueeze(3))) * torch.exp(-4*math.pi*self.complex_i/self.lambda1*point_range.unsqueeze(2).unsqueeze(3))\n",
    "        # # image_AllPoint = torch.abs(point_Amp.unsqueeze(2).unsqueeze(3)*torch.sinc(1/self.RangeRes*(self.Range_map.unsqueeze(0).unsqueeze(1)-point_range.unsqueeze(2).unsqueeze(3))) * torch.sinc(1/DopplerRes*(self.Dopple_map.unsqueeze(0).unsqueeze(1)-point_doppler.unsqueeze(2).unsqueeze(3))) * torch.exp(-4*math.pi*self.complex_i/self.lambda1*point_range.unsqueeze(2).unsqueeze(3)))\n",
    "        image_AllPoint = point_Amp.unsqueeze(2).unsqueeze(3)*gaussian_pdf(point_range.unsqueeze(2).unsqueeze(3), self.Range_map.unsqueeze(0).unsqueeze(1), self.RangeRes) * gaussian_pdf(point_doppler.unsqueeze(2).unsqueeze(3), self.Dopple_map.unsqueeze(0).unsqueeze(1), DopplerRes)\n",
    "        image = torch.sum(image_AllPoint,dim=1)\n",
    "\n",
    "        return image\n",
    "\n",
    "def plot_pointcloud(mesh, title=\"\"):\n",
    "    # Sample points uniformly from the surface of the mesh.\n",
    "    points = sample_points_from_meshes(mesh, 5000)\n",
    "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter3D(x, z, -y)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(60, 0)\n",
    "    ax.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "import os\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# Set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:3\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: CPU only, this will be slow!\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整体放缩系数\n",
    "scale_all = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入初始模型方式\n",
    "# 选择一种载入初始模型的方法\n",
    "flag = 2\n",
    "if flag == 0:\n",
    "    # 载入一个已有的Mesh模型\n",
    "    trg_obj = 'Geographos Radar-based, low-res(1).obj'\n",
    "    # trg_obj = 'dolphin.obj'\n",
    "    # trg_obj = 'wx_origin.obj'\n",
    "    # 读取卫星各项参数\n",
    "    # We read the target 3D model using load_obj\n",
    "    verts, faces, aux = load_obj(trg_obj)\n",
    "\n",
    "    # verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "    # faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "    # For this tutorial, normals and textures are ignored.\n",
    "    faces_idx = faces.verts_idx.to(device)\n",
    "    verts = verts.to(device)\n",
    "\n",
    "    # We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "    # (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "    # Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "    center = verts.mean(0)\n",
    "    verts = verts - center\n",
    "    scale = max(verts.abs().max(0)[0])\n",
    "    verts = verts / scale *10\n",
    "\n",
    "    # We construct a Meshes structure for the target mesh\n",
    "    trg_mesh = Meshes(verts=[verts], faces=[faces_idx])\n",
    "\n",
    "\n",
    "    # 为mesh添加材质信息\n",
    "    verts_rgb = torch.ones_like(trg_mesh.verts_packed())*255  # 使用纯白色作为默认颜色\n",
    "    verts_rgb = verts_rgb.unsqueeze(0)\n",
    "    textures = TexturesVertex(verts_features=verts_rgb)\n",
    "    trg_mesh.textures = textures\n",
    "\n",
    "    src_mesh = trg_mesh\n",
    "if flag == 1:\n",
    "    # 载入双球模型\n",
    "\n",
    "    # 创建初始模，两个球体\n",
    "    sphere1 = ico_sphere(4, device)\n",
    "    sphere2 = ico_sphere(4, device)\n",
    "\n",
    "    # 将第一个球体放大到1.5倍\n",
    "    vert1 = sphere2.verts_packed()\n",
    "    vert1 = vert1 * 1.5\n",
    "    sphere2 = Meshes(verts=[vert1], faces=[sphere2.faces_packed()])\n",
    "\n",
    "    # 计算放大后的球体的最大x坐标\n",
    "    max_x1 = sphere1.verts_packed()[:, 0].max()\n",
    "    # 计算第二个球体的最小x坐标\n",
    "    min_x2 = sphere2.verts_packed()[:, 0].min()\n",
    "\n",
    "    # 计算平移量，确保两球体有适当重叠\n",
    "    overlap = 0.1\n",
    "    shift = max_x1 - min_x2 + overlap\n",
    "\n",
    "    # 获取第二个球体的顶点并进行x方向平移\n",
    "    verts2 = sphere2.verts_packed() + torch.tensor([shift, 0, 0], device=device)\n",
    "\n",
    "    # 获取第一个球体的顶点（已经放大）\n",
    "    verts1 = sphere1.verts_packed()\n",
    "\n",
    "    # 合并两球体的顶点\n",
    "    verts = torch.cat([verts1, verts2], dim=0)\n",
    "\n",
    "    # 可以额外添加整体平移\n",
    "    verts = verts + torch.tensor([-1.5, 0, 0], device=device)\n",
    "\n",
    "    # 整体放缩\n",
    "    verts = verts * 3\n",
    "\n",
    "    # 合并面片，并更新第二个球体的面片索引\n",
    "    faces1 = sphere1.faces_packed()\n",
    "    faces2 = sphere2.faces_packed() + sphere1.verts_packed().shape[0]  # 更新索引\n",
    "\n",
    "    # 合并面片数据\n",
    "    faces = torch.cat([faces1, faces2], dim=0)\n",
    "\n",
    "    # 创建黏连的球体网格\n",
    "    src_mesh = Meshes(verts=[verts], faces=[faces])\n",
    "\n",
    "if flag == 2:\n",
    "    def create_ellipsoid(level, device, scale_factors=(1.5, 1.0, 0.7)):\n",
    "        \"\"\"\n",
    "        创建椭球体\n",
    "        \n",
    "        参数:\n",
    "            level: ico_sphere 的细分级别\n",
    "            device: 计算设备\n",
    "            scale_factors: (x, y, z) 缩放因子\n",
    "        \"\"\"\n",
    "        # 创建基础球体\n",
    "        sphere = ico_sphere(level, device)\n",
    "        \n",
    "        # 获取球体的顶点和面\n",
    "        verts = sphere.verts_packed()\n",
    "        faces = sphere.faces_packed()\n",
    "        \n",
    "        # 对顶点进行缩放以形成椭球体\n",
    "        x_scale, y_scale, z_scale = scale_factors\n",
    "        scaled_verts = verts.clone()\n",
    "        scaled_verts[:, 0] *= x_scale  # x方向缩放\n",
    "        scaled_verts[:, 1] *= y_scale  # y方向缩放\n",
    "        scaled_verts[:, 2] *= z_scale  # z方向缩放\n",
    "        \n",
    "        # 创建新的网格\n",
    "        ellipsoid = Meshes(verts=[scaled_verts], faces=[faces])\n",
    "        \n",
    "        return ellipsoid\n",
    "    \n",
    "    sphere1 = create_ellipsoid(4, device, scale_factors=(2.0, 1.0, 1.0))\n",
    "\n",
    "    vert = sphere1.verts_packed()\n",
    "    vert = vert * 3\n",
    "\n",
    "    src_mesh = Meshes(verts=[vert], faces=[sphere1.faces_packed()])\n",
    "\n",
    "# 可视化src_mesh\n",
    "plot_pointcloud(src_mesh, title=\"Target mesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    # 分割字符串中的数字并将它们转换为整数\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def loaddata(folder_path):\n",
    "    '''\n",
    "    输入文件夹路径，输出数据集\n",
    "    '''\n",
    "    # 获取文件夹中的所有文件和子文件夹\n",
    "    items = os.listdir(folder_path)\n",
    "    # 过滤出所有文件（排除子文件夹）\n",
    "    files = [item for item in items if os.path.isfile(os.path.join(folder_path, item)) and item.endswith('.npz')]\n",
    "    files_sorted = sorted(files, key=natural_sort_key)\n",
    "    #载入数据\n",
    "    images = []\n",
    "    LOS_dirs = []\n",
    "    omegas = []\n",
    "    max_pixel = []\n",
    "    for file in files_sorted:\n",
    "        full_path = folder_path+\"/\"+file\n",
    "        data = np.load(full_path)\n",
    "        image = torch.from_numpy(data['image']).to(device)\n",
    "        LOS_dir = torch.from_numpy(data['LOS']).to(device)\n",
    "        omega = torch.from_numpy(data['rotation_axis']).to(device)\n",
    "        images.append(image)\n",
    "        LOS_dirs.append(LOS_dir)\n",
    "        omegas.append(omega)\n",
    "    max_pixel = [torch.max(image) for image in images]\n",
    "    max_pixel_all = max(max_pixel, key=lambda x: x.item())\n",
    "    images_normalize = [image/max_pixel_all for image in images]\n",
    "    return images_normalize,LOS_dirs,omegas\n",
    "\n",
    "\n",
    "# 创建渲染器\n",
    "ISAR_render1 = ISAR_render(device)\n",
    "\n",
    "# 输入数据1\n",
    "# image_batch = np.load('./2024wb_peizhun/2024wb.npz')\n",
    "# image_input = image_batch['image_batch']\n",
    "\n",
    "# 输入数据2\n",
    "image_input,_,_ = loaddata('/DATA/disk1/asteroid/asteroid_inverse/Instant-ngp/new_dataset/sys_data/arr/30du_5dB')\n",
    "# 将列表转换为torch\n",
    "image_input = torch.stack(image_input, dim=0)\n",
    "image_input = image_input.to(device)\n",
    "print(image_input.shape)\n",
    "image_input = torch.abs(image_input)\n",
    "\n",
    "plt.imshow(image_input[0,:,:].detach().cpu(),cmap='hot')\n",
    "# 数据归一化\n",
    "max_values, _ = torch.max(image_input, dim=2)\n",
    "max_values_dim1, _ = torch.max(max_values, dim=1)\n",
    "image_trg = image_input/max_values_dim1.unsqueeze(1).unsqueeze(2)\n",
    "print(image_trg.shape)\n",
    "# 第零维倒序\n",
    "# image_trg = torch.flip(image_trg, dims=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成37组雷达视线方向\n",
    "def vec_rot(vec,axis_x,axis_y,axis_z,theta):\n",
    "\n",
    "    axis_x = axis_x.expand(theta.shape)\n",
    "    axis_y = axis_y.expand(theta.shape)\n",
    "    axis_z = axis_z.expand(theta.shape)\n",
    "\n",
    "    c = torch.cos(theta)\n",
    "    s = torch.sin(theta)\n",
    "    one_c = 1 - c\n",
    "\n",
    "    Rotmat = torch.stack([\n",
    "        torch.stack([axis_x**2 * one_c + c, axis_x * axis_y * one_c - axis_z * s, axis_x * axis_z * one_c + axis_y * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_y * one_c + axis_z * s, axis_y**2 * one_c + c, axis_y * axis_z * one_c - axis_x * s], dim=-1),\n",
    "        torch.stack([axis_x * axis_z * one_c - axis_y * s, axis_y * axis_z * one_c + axis_x * s, axis_z**2 * one_c + c], dim=-1)\n",
    "    ], dim=-2)\n",
    "\n",
    "    vec_rot = torch.matmul(Rotmat,vec.unsqueeze(1)).squeeze(2)\n",
    "\n",
    "    return vec_rot\n",
    "\n",
    "SpinAxis = torch.tensor([0,0,1.0], device=device)\n",
    "Omega = torch.tensor([0.004532090125293*1], device=device)\n",
    "SpinAxis = SpinAxis.unsqueeze(0)\n",
    "Omega = Omega.unsqueeze(0)\n",
    "\n",
    "batch = 30\n",
    "\n",
    "RadarLos = torch.tensor([-math.sqrt(3)/2,0,1/2], device=device)\n",
    "# RadarLos = torch.tensor([-1/2,0,-math.sqrt(3)/2], device=device)\n",
    "theta = torch.linspace(0,math.pi-math.pi/30,batch).to(device)\n",
    "\n",
    "axis_x = torch.tensor([0.0], device=device)\n",
    "axis_y = torch.tensor([0.0], device=device)\n",
    "axis_z = torch.tensor([1.0], device=device)\n",
    "omega_vec = torch.stack((axis_x.repeat(batch),axis_y.repeat(batch),axis_z.repeat(batch)),dim = 1)\n",
    "# print(omega_vec)\n",
    "Round_radar_los = vec_rot(RadarLos,axis_x,axis_y,axis_z,theta)\n",
    "Round_radar_los_real = vec_rot(RadarLos,axis_x,axis_y,axis_z,-theta)\n",
    "\n",
    "print(Round_radar_los)\n",
    "print(Round_radar_los.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成测试数据\n",
    "image_src = ISAR_render1(src_mesh, Round_radar_los[0:25], SpinAxis[0:25], Omega[0:25])\n",
    "# 取模归一化\n",
    "image_src = torch.abs(image_src)\n",
    "max1,_ = torch.max(image_src,dim=2)\n",
    "max2,_ = torch.max(max1,dim=1)\n",
    "image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "plt.figure()\n",
    "plt.imshow(image_src[0,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_trg[0,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_src[4,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_trg[4,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_src[9,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_trg[9,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_trg[12,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_src[15,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_trg[15,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_src[20,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_trg[20,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_src[24,:,:].detach().cpu(),cmap='hot')\n",
    "plt.figure()\n",
    "plt.imshow(image_trg[24,:,:].detach().cpu(),cmap='hot')\n",
    "plt.colorbar()\n",
    "\n",
    "# 将图片转换为numpy,并保存为png文件\n",
    "image_max = image_src.max().detach().cpu().numpy()\n",
    "# print(image_max)\n",
    "image_min = image_src.min().detach().cpu().numpy()\n",
    "# 创建文件夹\n",
    "# os.makedirs(\"./1620_point\",exist_ok=True)\n",
    "import cv2\n",
    "import numpy as np\n",
    "for i in range(0,10):\n",
    "    image_i = image_src[i,:,:].squeeze(0).detach().cpu().numpy()\n",
    "    image_i = (image_i - image_min)/(image_max-image_min)\n",
    "    LOS_real = Round_radar_los_real[i].detach().cpu().numpy()\n",
    "    rotation_axis = omega_vec[i].detach().cpu().numpy()\n",
    "    # np.savez(\"./1620_point/image\"+str(i)+\".npz\", image=image_i, LOS = LOS_real, rotation_axis = rotation_axis)\n",
    "    image_i = np.uint8(image_i*255)\n",
    "    # cv2.imwrite(\"./1620_point/image\"+str(i)+\".png\",image_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 生成36组雷达视线方向\n",
    "# def vec_rot(vec,axis_x,axis_y,axis_z,theta):\n",
    "\n",
    "#     axis_x = axis_x.expand(theta.shape)\n",
    "#     axis_y = axis_y.expand(theta.shape)\n",
    "#     axis_z = axis_z.expand(theta.shape)\n",
    "\n",
    "#     c = torch.cos(theta)\n",
    "#     s = torch.sin(theta)\n",
    "#     one_c = 1 - c\n",
    "\n",
    "#     Rotmat = torch.stack([\n",
    "#         torch.stack([axis_x**2 * one_c + c, axis_x * axis_y * one_c - axis_z * s, axis_x * axis_z * one_c + axis_y * s], dim=-1),\n",
    "#         torch.stack([axis_x * axis_y * one_c + axis_z * s, axis_y**2 * one_c + c, axis_y * axis_z * one_c - axis_x * s], dim=-1),\n",
    "#         torch.stack([axis_x * axis_z * one_c - axis_y * s, axis_y * axis_z * one_c + axis_x * s, axis_z**2 * one_c + c], dim=-1)\n",
    "#     ], dim=-2)\n",
    "\n",
    "#     vec_rot = torch.matmul(Rotmat,vec.unsqueeze(1)).squeeze(2)\n",
    "\n",
    "#     return vec_rot\n",
    "\n",
    "# batch = 12\n",
    "\n",
    "# RadarLos1 = torch.tensor([-1.0,0,0], device=device)\n",
    "# RadarLos2 = torch.tensor([-1/2,0,-math.sqrt(3)/2], device=device)\n",
    "# RadarLos3 = torch.tensor([-1/2,0,math.sqrt(3)/2], device=device)\n",
    "# theta = torch.linspace(0,2*math.pi,batch).to(device)\n",
    "\n",
    "# axis_x = torch.tensor([0.0], device=device)\n",
    "# axis_y = torch.tensor([0.0], device=device)\n",
    "# axis_z = torch.tensor([1.0], device=device)\n",
    "# Round_radar_los1 = vec_rot(RadarLos1,axis_x,axis_y,axis_z,theta)\n",
    "# Round_radar_los2 = vec_rot(RadarLos2,axis_x,axis_y,axis_z,theta)\n",
    "# Round_radar_los3 = vec_rot(RadarLos3,axis_x,axis_y,axis_z,theta)\n",
    "\n",
    "# Round_radar_los = torch.cat([Round_radar_los1,Round_radar_los2,Round_radar_los3],dim=-2)\n",
    "# print(Round_radar_los)\n",
    "# print(Round_radar_los.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpinAxis = torch.tensor([0,0,1.0], device=device)\n",
    "# Omega = torch.tensor([2*math.pi/3600/6], device=device)\n",
    "# SpinAxis = SpinAxis.unsqueeze(0)\n",
    "# Omega = Omega.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def points_normal_visual(points,normals):\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     x, y, z = points.clone().detach().cpu().squeeze().unbind(1)\n",
    "#     x_normal, y_normal, z_normal = normals.clone().detach().cpu().squeeze().unbind(1)\n",
    "#     # 绘制点云\n",
    "#     ax.scatter(x, y, z, color='b', marker='o', alpha=0.5)\n",
    "\n",
    "#     # 绘制法向量\n",
    "#     # 此处通过 quiver 函数, scale=10 调整法向量的长度\n",
    "#     ax.quiver(\n",
    "#         x, y, z,\n",
    "#         x_normal, y_normal, z_normal,\n",
    "#         length=1, color='r', normalize=True\n",
    "#     )\n",
    "\n",
    "#     # 设置坐标轴标签\n",
    "#     ax.set_xlabel('X Axis')\n",
    "#     ax.set_ylabel('Y Axis')\n",
    "#     ax.set_zlabel('Z Axis')\n",
    "\n",
    "#     # 设置标题\n",
    "#     ax.set_title('Point Cloud and Normals')\n",
    "#     ax.view_init(40, 30)\n",
    "#     # 显示图形\n",
    "#     plt.show()\n",
    "\n",
    "# deform_verts = torch.full(src_mesh.verts_packed().shape, 0.0, device=device, requires_grad=True)\n",
    "\n",
    "# sampled_points_src, point_normals_src= sample_points_from_meshes(src_mesh, 2000,return_normals = True)\n",
    "# points_normal_opt = torch.tensor(point_normals_src,requires_grad=True)\n",
    "\n",
    "# optimizer = torch.optim.Adam([deform_verts,points_normal_opt], lr=0.01)\n",
    "\n",
    "# points_normal_visual(sampled_points_src,points_normal_opt)\n",
    "\n",
    "# image_src = ISAR_render1(src_mesh, Round_radar_los[0:3,:], SpinAxis, Omega)\n",
    "\n",
    "# image_src = torch.abs(image_src)\n",
    "# max1,_ = torch.max(image_src,dim=2)\n",
    "# max2,_ = torch.max(max1,dim=1)\n",
    "# image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(image_src[0,:,:].detach().cpu(),cmap='hot')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deform_verts = torch.full(src_mesh.verts_packed().shape, 0.0, device=device, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.Adam([deform_verts], lr=0.05)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=4000,eta_min=5e-4)\n",
    "\n",
    "\n",
    "# Number of optimization steps\n",
    "Niter = 4000\n",
    "# Weight for the image loss\n",
    "w_image = 0.0003\n",
    "# Weight for mesh edge loss\n",
    "w_edge = 0.35\n",
    "# Weight for mesh normal consistency\n",
    "w_normal = 2\n",
    "# Weight for mesh laplacian smoothing\n",
    "w_laplacian = 5\n",
    "# Plot period for the losses\n",
    "plot_period = 1000\n",
    "loop = tqdm(range(Niter))\n",
    "\n",
    "image_losses = []\n",
    "laplacian_losses = []\n",
    "edge_losses = []\n",
    "normal_losses = []\n",
    "\n",
    "for i in loop:\n",
    "    # Initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Deform the mesh\n",
    "    new_src_mesh = src_mesh.offset_verts(deform_verts)\n",
    "    \n",
    "    # 每轮选取三个视角进行训练\n",
    "    random_numbers = np.random.choice(range(0, 30), 6, replace=False)\n",
    "    image_src = ISAR_render1(new_src_mesh, Round_radar_los[random_numbers,:], SpinAxis, Omega)\n",
    "    # 取模归一化\n",
    "    image_src = torch.abs(image_src)\n",
    "    max1,_ = torch.max(image_src,dim=2)\n",
    "    max2,_ = torch.max(max1,dim=1)\n",
    "    image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "    image_trg_sample = image_trg[random_numbers,:,:]\n",
    "    \n",
    "    # 计算简单的mse\n",
    "    loss_image = torch.sum((image_trg_sample - image_src)**2)\n",
    "    \n",
    "    # and (b) the edge length of the predicted mesh\n",
    "    loss_edge = mesh_edge_loss(new_src_mesh)\n",
    "    \n",
    "    # mesh normal consistency\n",
    "    loss_normal = mesh_normal_consistency(new_src_mesh)\n",
    "    \n",
    "    # mesh laplacian smoothing\n",
    "    loss_laplacian = mesh_laplacian_smoothing(new_src_mesh, method=\"uniform\")\n",
    "    \n",
    "    # Weighted sum of the losses\n",
    "    loss = loss_image * w_image + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
    "    \n",
    "    # Print the losses\n",
    "    loop.set_description('total_loss = %.6f' % loss)\n",
    "    \n",
    "    # Save the losses for plotting\n",
    "    image_losses.append(float(loss_image.detach().cpu()))\n",
    "    edge_losses.append(float(loss_edge.detach().cpu()))\n",
    "    normal_losses.append(float(loss_normal.detach().cpu()))\n",
    "    laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
    "    \n",
    "    # Plot mesh\n",
    "    if i % plot_period == 0:\n",
    "        plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)\n",
    "        plt.figure()\n",
    "        plt.imshow(image_src[0,:,:].detach().cpu(),cmap='hot')\n",
    "        plt.colorbar()\n",
    "        plt.figure()\n",
    "        plt.imshow(image_trg_sample[0,:,:].detach().cpu(),cmap='hot')\n",
    "        plt.colorbar()\n",
    "        \n",
    "    # Optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_image = loss_image\n",
    "\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "ax = fig.gca()\n",
    "ax.plot([x*w_image for x in image_losses], label=\"image losses\")\n",
    "ax.plot([x*w_edge for x in edge_losses], label=\"edge loss\")\n",
    "ax.plot([x*w_normal for x in normal_losses], label=\"normal loss\")\n",
    "ax.plot([x*w_laplacian for x in laplacian_losses], label=\"laplacian loss\")                                                                                                                                  \n",
    "ax.legend(fontsize=\"16\")\n",
    "ax.set_xlabel(\"Iteration\", fontsize=\"16\")\n",
    "ax.set_ylabel(\"Loss\", fontsize=\"16\")\n",
    "ax.set_title(\"Loss vs iterations\", fontsize=\"16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "image_src = ISAR_render1(new_src_mesh, Round_radar_los[0:6,:], SpinAxis, Omega)\n",
    "# 取模归一化\n",
    "image_src = torch.abs(image_src)\n",
    "max1,_ = torch.max(image_src,dim=2)\n",
    "max2,_ = torch.max(max1,dim=1)\n",
    "image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "plt.figure()\n",
    "plt.imshow(image_src[0,:,:].detach().cpu(),cmap='hot')\n",
    "\n",
    "filename = \"/DATA/disk1/asteroid/asteroid_inverse/Instant-ngp/new_dataset/result/snr/\"\n",
    "fullname = filename + \"arr/5db\"\n",
    "\n",
    "# 生成保存路径\n",
    "if not os.path.exists(fullname):\n",
    "    os.makedirs(fullname)\n",
    "for i in range(30):\n",
    "    image_src = ISAR_render1(new_src_mesh, Round_radar_los[i:i+1,:], SpinAxis, Omega)\n",
    "    image_src = torch.abs(image_src)\n",
    "    max1,_ = torch.max(image_src,dim=2)\n",
    "    max2,_ = torch.max(max1,dim=1)\n",
    "    image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "    image_save = image_src[0,:,:].detach().cpu()\n",
    "\n",
    "    # 确保保存路径存在\n",
    "    if not os.path.exists(fullname + \"/npz\"):\n",
    "        os.makedirs(fullname + \"/npz\")\n",
    "    # 将图片保存为npz文件\n",
    "    np.savez(fullname + \"/npz/image\" + str(i) + \".npz\", image=image_save.numpy())\n",
    "\n",
    "    # if i%5==0:\n",
    "    #     plt.figure()\n",
    "    #     plt.imshow(image_save,cmap='hot')  \n",
    "\n",
    "    array = image_save.squeeze(0).numpy() * 255  # 转换为数组并缩放到 0-255 范围\n",
    "    array = array.astype('uint8')  # 将类型转换为 8 位整数\n",
    "\n",
    "    # 创建一个 PIL 图片对象\n",
    "    # 转换为hot图像\n",
    "    # 表示hot图像\n",
    "    # image = Image.fromarray(array, mode='')  \n",
    "    image = Image.fromarray(array, mode='L')  # 'L' 模式表示灰度图像\n",
    "\n",
    "    # 确定保存路径\n",
    "    output_folder = fullname + \"/images\"\n",
    "    image_name = 'image' + str(i) + '.png'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, image_name)\n",
    "\n",
    "    # 保存图片\n",
    "    image.save(output_path)\n",
    "\n",
    "save_obj(fullname + \"/model.obj\", verts=new_src_mesh.verts_packed(), faces=new_src_mesh.faces_packed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_obj = 'Geographos Radar-based, low-res(1).obj'\n",
    "# 读取卫星各项参数\n",
    "# We read the target 3D model using load_obj\n",
    "verts, faces, aux = load_obj(trg_obj)\n",
    "\n",
    "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "# For this tutorial, normals and textures are ignored.\n",
    "faces_idx = faces.verts_idx.to(device)\n",
    "verts = verts.to(device)\n",
    "\n",
    "# We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "# (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "# Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "center = verts.mean(0)\n",
    "verts = verts - center\n",
    "scale = max(verts.abs().max(0)[0])\n",
    "verts = verts / scale *5\n",
    "\n",
    "# We construct a Meshes structure for the target mesh\n",
    "trg_mesh = Meshes(verts=[verts], faces=[faces_idx])\n",
    "\n",
    "plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)\n",
    "plot_pointcloud(trg_mesh, title=\"iter: %d\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_individually(trg_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_individually(new_src_mesh)\n",
    "# threed_model_path = fullname + \"/3dmodel\"\n",
    "# if not os.path.exists(threed_model_path):\n",
    "#     os.makedirs(threed_model_path)\n",
    "# 将模型保存到给定路径\n",
    "save_obj(fullname + \"/model.obj\", verts=new_src_mesh.verts_packed(), faces=new_src_mesh.faces_packed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_individually(new_src_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbers = np.random.choice(range(0, 25), 6, replace=False)\n",
    "image_src = ISAR_render1(new_src_mesh, Round_radar_los[random_numbers,:], SpinAxis, Omega)\n",
    "image_trg_sample = image_trg[random_numbers,:,:]\n",
    "image_src = torch.abs(image_src)\n",
    "max1,_ = torch.max(image_src,dim=2)\n",
    "max2,_ = torch.max(max1,dim=1)\n",
    "image_src = image_src/max2.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image_src[0,:,:].detach().cpu(),cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(image_trg_sample[0,:,:].detach().cpu(),cmap='hot')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pointcloud(new_src_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts = new_src_mesh.verts_packed()\n",
    "faces = new_src_mesh.faces_packed()\n",
    "\n",
    "save_obj('/point_inverse/result2.obj', verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
