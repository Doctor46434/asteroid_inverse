{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[21]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 412.00 MiB. GPU 4 has a total capacity of 31.73 GiB of which 92.19 MiB is free. Process 3116151 has 7.69 GiB memory in use. Process 3121230 has 22.97 GiB memory in use. Including non-PyTorch memory, this process has 998.00 MiB memory in use. Of the allocated memory 472.09 MiB is allocated by PyTorch, and 161.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 265\u001b[0m\n\u001b[1;32m    262\u001b[0m images,LOS_dirs,omegas \u001b[38;5;241m=\u001b[39m loaddata(folder_path)\n\u001b[1;32m    264\u001b[0m omegas_batch_tensor,LOS_dirs_batch_tensor,range_profile_batch_tensor,doppler_profil_num_tensor \u001b[38;5;241m=\u001b[39m picture_sample(images,LOS_dirs,omegas,batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m--> 265\u001b[0m distance_profile_batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatchrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43momegas_batch_tensor\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43momega_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLOS_dirs_batch_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdoppler_profil_num_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# print(LOS_dirs)\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# print(LOS_dirs_batch_tensor)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m range_image1 \u001b[38;5;241m=\u001b[39m distance_profile_batch\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "Cell \u001b[0;32mIn[1], line 156\u001b[0m, in \u001b[0;36mbatchrender\u001b[0;34m(omega, LOS, model, doppler_num)\u001b[0m\n\u001b[1;32m    154\u001b[0m     LOS_coding \u001b[38;5;241m=\u001b[39m position_code_LOS(LOS)\n\u001b[1;32m    155\u001b[0m     LOS_coding \u001b[38;5;241m=\u001b[39m ((LOS_coding\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(batch_size,distance_gap,n_gap,\u001b[38;5;241m27\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m27\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m     xyzLOS_coding \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz_coding\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLOS_coding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     xyz \u001b[38;5;241m=\u001b[39m doppler_map[torch\u001b[38;5;241m.\u001b[39marange(batch_size),doppler_num,:]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m distance_map\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m n_random_map\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 412.00 MiB. GPU 4 has a total capacity of 31.73 GiB of which 92.19 MiB is free. Process 3116151 has 7.69 GiB memory in use. Process 3121230 has 22.97 GiB memory in use. Including non-PyTorch memory, this process has 998.00 MiB memory in use. Of the allocated memory 472.09 MiB is allocated by PyTorch, and 161.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 变更旋转参数后的成像程序\n",
    "import torch\n",
    "import numpy as np\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "class NeRF(nn.Module):\n",
    "    def __init__(self, D=8, W=256, input_ch=3, input_ch_views=3, output_ch=2, skips=[4], use_viewdirs=True):\n",
    "        \"\"\"\n",
    "        D: 深度，多少层网络\n",
    "        W: 网络内的channel 宽度\n",
    "        input_ch: xyz的宽度\n",
    "        input_ch_views: direction的宽度\n",
    "        output_ch: 这个参数尽在 use_viewdirs=False的时候会被使用\n",
    "        skips: 类似resnet的残差连接，表明在第几层进行连接\n",
    "        use_viewdirs:\n",
    "\n",
    "        网络输入已经被位置编码后的参数，输入为[64*bs,90]，输出为[64*bs，2]，一位是体积密度，一位是后向散射系数\n",
    "        \"\"\"\n",
    "        super(NeRF, self).__init__()\n",
    "        self.D = D\n",
    "        self.W = W\n",
    "        self.input_ch = input_ch\n",
    "        self.input_ch_views = input_ch_views\n",
    "        self.skips = skips\n",
    "        self.use_viewdirs = use_viewdirs\n",
    "\n",
    "        # 神经网络,MLP\n",
    "        # 3D的空间坐标进入的网络\n",
    "        # 这个跳跃连接层是直接拼接，不是resnet的那种相加\n",
    "        self.pts_linears = nn.ModuleList(\n",
    "            [nn.Linear(input_ch, W)] + [nn.Linear(W, W) if i not in self.skips else nn.Linear(W + input_ch, W) for i in\n",
    "                                        range(D - 1)])\n",
    "\n",
    "        # 这里channel削减一半 128\n",
    "        ### Implementation according to the official code release (https://github.com/bmild/nerf/blob/master/run_nerf_helpers.py#L104-L105)\n",
    "        self.views_linears = nn.ModuleList([nn.Linear(input_ch_views + W, W // 2)])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if use_viewdirs:\n",
    "            # 特征\n",
    "            self.feature_linear = nn.Linear(W, W)\n",
    "            # 体积密度,一个值\n",
    "            self.alpha_linear = nn.Linear(W, 1)\n",
    "            # 后向散射系数，一个值\n",
    "            self.rho_linear = nn.Linear(W // 2, 1)\n",
    "        else:\n",
    "            self.output_linear = nn.Linear(W, output_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x [bs*64, 90]\n",
    "        # input_pts [bs*64, 63]\n",
    "        # input_views [bs*64,27]\n",
    "        input_pts, input_views = torch.split(x, [self.input_ch, self.input_ch_views], dim=-1)\n",
    "\n",
    "        h = input_pts\n",
    "\n",
    "        for i, l in enumerate(self.pts_linears):\n",
    "\n",
    "            h = self.pts_linears[i](h)\n",
    "            h = F.relu(h)\n",
    "            # 第四层后相加\n",
    "            if i in self.skips:\n",
    "                h = torch.cat([input_pts, h], -1)\n",
    "\n",
    "        if self.use_viewdirs:\n",
    "            # alpha只与xyz有关\n",
    "            alpha = self.alpha_linear(h)\n",
    "            feature = self.feature_linear(h)\n",
    "            # rho与xyz和d都有关\n",
    "            h = torch.cat([feature, input_views], -1)\n",
    "\n",
    "            for i, l in enumerate(self.views_linears):\n",
    "                h = self.views_linears[i](h)\n",
    "                h = F.relu(h)\n",
    "\n",
    "            sigma = self.rho_linear(h)\n",
    "            alpha = self.relu(alpha) \n",
    "            sigma = self.sigmoid(sigma)\n",
    "            outputs = torch.cat([alpha, sigma], -1)\n",
    "        else:\n",
    "            outputs = self.output_linear(h)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def batchrender(omega,LOS,model,doppler_num):\n",
    "    '''\n",
    "    omega为一个[bs,3]变量，指向旋转轴方向，模值为角速度\n",
    "    LOS为一个[bs,3]变量，方向为视线方向指向物体，模值为1\n",
    "    model是nerf模型，将一个已经进行位置编码后的位置和视线向量输入进model,可以返回这个位置的体积密度和散射系数\n",
    "    doppler_num为一个[bs]变量，确定了渲染后光线所在的位置\n",
    "    '''\n",
    "    # 确定回波波长\n",
    "    fc = torch.tensor([9.7e9]).to(device)\n",
    "    c = torch.tensor([299792458]).to(device)\n",
    "    lambda0 = c/fc\n",
    "    # 确定网格参数\n",
    "    distance_max = 60\n",
    "    distance_min = -60\n",
    "    distance_gap = 100\n",
    "    doppler_max = 15\n",
    "    doppler_min = -15\n",
    "    doppler_gap = 100\n",
    "    n_max = 60\n",
    "    n_min = -60\n",
    "    n_gap = 120\n",
    "    # 确定输入batch_size\n",
    "    batch_size,len = omega.shape\n",
    "    # 确定每个batch_size输入的投影平面\n",
    "    omega_norm = torch.linalg.norm(omega,dim = 1)\n",
    "    omega_normlize = omega/omega_norm.unsqueeze(1)\n",
    "    Doppler_vector = torch.cross(LOS,omega,dim=1)\n",
    "    LOSomega_sin_angel = torch.linalg.norm(Doppler_vector,dim=1)/(torch.linalg.norm(omega,dim=1)*torch.linalg.norm(LOS,dim=1))\n",
    "    Doppler_vector = Doppler_vector/torch.linalg.norm(Doppler_vector,dim = 1).unsqueeze(1)\n",
    "    # 绘制投影坐标\n",
    "    distance = torch.linspace(distance_min,distance_max,distance_gap).to(device)\n",
    "    distance = distance.repeat(batch_size,1)\n",
    "    distance_delta = torch.tensor((distance_max-distance_min)/distance_gap).to(device)\n",
    "    doppler = torch.linspace(doppler_min,doppler_max,doppler_gap).repeat(batch_size,1).to(device)\n",
    "    doppler = doppler*4/LOSomega_sin_angel.unsqueeze(1)\n",
    "    distance_map = distance.unsqueeze(2)*LOS.unsqueeze(1)\n",
    "    doppler_map = doppler.unsqueeze(2)*Doppler_vector.unsqueeze(1)\n",
    "    # 确定投影平面法向量\n",
    "    n = torch.cross(LOS,Doppler_vector,dim=1)\n",
    "    n = n/torch.linalg.norm(n,dim = 1).unsqueeze(1)\n",
    "    # 对投影平面法向量进行随机采样\n",
    "    n_array = torch.linspace(n_min,n_max,n_gap+1).to(device)\n",
    "    n_array = n_array.repeat(batch_size,distance_gap,1)\n",
    "    # 非随机采样\n",
    "    # n_random_array = n_array[:,:,0:-1] + (n_array[:,:,1:] - n_array[:,:,0:-1])*torch.ones(batch_size,distance_gap,n_gap).to(device)*0.5\n",
    "    # # 随机采样\n",
    "    n_random_array = n_array[:,:,0:-1] + (n_array[:,:,1:] - n_array[:,:,0:-1])*torch.rand(batch_size,distance_gap,n_gap).to(device)\n",
    "    n_random_map = n_random_array.unsqueeze(3)*n.unsqueeze(1).unsqueeze(2)\n",
    "    # 计算不同随机法向量之间的间隔\n",
    "    start_n = n.unsqueeze(1).unsqueeze(2)*torch.tensor(n_min).float().to(device)\n",
    "    start_n = start_n * torch.ones(batch_size,distance_gap,1,3).to(device)\n",
    "    n_random_map_temp = torch.cat((start_n,n_random_map),dim=2)\n",
    "    n_delta = torch.norm(n_random_map_temp[:,:,0:-1,:]-n_random_map,dim=3)\n",
    "\n",
    "    # 计算所有需要输入网络的坐标\n",
    "    code_flag = 1\n",
    "    if code_flag == 1:\n",
    "        xyz = doppler_map[torch.arange(batch_size),doppler_num,:].unsqueeze(1).unsqueeze(2) + distance_map.unsqueeze(2) + n_random_map\n",
    "        xyz_coding = positon_code_xyz(xyz)\n",
    "        LOS_coding = position_code_LOS(LOS)\n",
    "        LOS_coding = ((LOS_coding.unsqueeze(1).unsqueeze(2))*torch.ones(batch_size,distance_gap,n_gap,27).to(device)).view(-1,27)\n",
    "        xyzLOS_coding = torch.cat((xyz_coding,LOS_coding),dim=1)\n",
    "    else:\n",
    "        xyz = doppler_map[torch.arange(batch_size),doppler_num,:].unsqueeze(1).unsqueeze(2) + distance_map.unsqueeze(2) + n_random_map\n",
    "        xyz_coding = xyz.view(-1,3)\n",
    "        LOS_coding = ((LOS.unsqueeze(1).unsqueeze(2))*torch.ones(batch_size,distance_gap,n_gap,3).to(device)).view(-1,3)\n",
    "        print(LOS_coding)\n",
    "        xyzLOS_coding = torch.cat((xyz_coding,LOS_coding),dim=1)\n",
    "    output = model(xyzLOS_coding)\n",
    "    output = output.view(batch_size,distance_gap,n_gap,2)\n",
    "    render_equaltion = 1\n",
    "    if render_equaltion == 1:\n",
    "        Ti = torch.cumprod(torch.exp(-output[:,:,:,0]*distance_delta),dim=1)\n",
    "        distance_profile = torch.sum(output[:,:,:,0]*(1-torch.exp(-output[:,:,:,1]*n_delta))*Ti,dim=2)\n",
    "    else:\n",
    "        Ti = torch.cumprod(torch.exp(-output[:,:,:,0]**2*distance_delta),dim=1)\n",
    "        distance_profile = torch.sum(output[:,:,:,0]*output[:,:,:,1]*n_delta*Ti,dim=2)\n",
    "\n",
    "    return distance_profile\n",
    "\n",
    "def positon_code_xyz(xyz):\n",
    "    code_len = 10\n",
    "    batch_size,distance,n,dimension = xyz.shape\n",
    "    xyz = xyz.view(-1,dimension)\n",
    "    xyz = xyz/100\n",
    "    position_coding = torch.zeros_like(xyz).to(device)\n",
    "    position_coding = position_coding.repeat(1,code_len*2)\n",
    "    div_term = 2 ** torch.arange(0,code_len,step=1).to(device)\n",
    "    position_coding[:,0::2] = torch.sin((xyz.unsqueeze(1) * math.pi * div_term.unsqueeze(1).unsqueeze(0)).view(batch_size*distance*n,-1))\n",
    "    position_coding[:,1::2] = torch.cos((xyz.unsqueeze(1) * math.pi * div_term.unsqueeze(1).unsqueeze(0)).view(batch_size*distance*n,-1))\n",
    "    position_coding = torch.cat((xyz,position_coding),dim=1)\n",
    "    \n",
    "    return position_coding\n",
    "\n",
    "def position_code_LOS(LOS):\n",
    "    code_len = 4\n",
    "    batch_size,dimension = LOS.shape\n",
    "    position_coding = torch.zeros_like(LOS).to(device)\n",
    "    position_coding = position_coding.repeat(1,code_len*2)\n",
    "    div_term = 2 ** torch.arange(0,code_len,step=1).to(device)\n",
    "    position_coding[:,0::2] = torch.sin((LOS.unsqueeze(1) * div_term.unsqueeze(1).unsqueeze(0)).view(batch_size,-1))\n",
    "    position_coding[:,1::2] = torch.cos((LOS.unsqueeze(1) * div_term.unsqueeze(1).unsqueeze(0)).view(batch_size,-1))\n",
    "    position_coding = torch.cat((LOS,position_coding),dim=1)\n",
    "\n",
    "    return position_coding\n",
    "\n",
    "def picture_sample(images,LOS_dirs,omegas,batch_size):\n",
    "    temp_num = random.sample(range(40),1)\n",
    "    # temp_num = [0]\n",
    "    print(temp_num)\n",
    "    temp = [t*100 for t in temp_num] + np.arange(100)\n",
    "    data_num = [x//100 for x in temp]\n",
    "    doppler_numbers = [x % 100 for x in temp]\n",
    "    \n",
    "    LOS_dirs_batch = [LOS_dirs[x] for x in data_num]\n",
    "    omegas_batch = [omegas[x] for x in data_num]\n",
    "    range_profile_batch = [images[x][y,:] for x,y in zip(data_num,doppler_numbers)]\n",
    "\n",
    "    omegas_batch_tensor = torch.stack(omegas_batch).to(device)\n",
    "    LOS_dirs_batch_tensor = torch.stack(LOS_dirs_batch).to(device)\n",
    "    range_profile_batch_tensor = torch.stack(range_profile_batch).to(device)\n",
    "    doppler_profil_num_tensor = torch.tensor(doppler_numbers).long().to(device)\n",
    "\n",
    "    # range_image = range_profile_batch_tensor.detach().cpu()\n",
    "    # plt.imshow(range_image)\n",
    "    # plt.show()\n",
    "    \n",
    "    return omegas_batch_tensor,LOS_dirs_batch_tensor,range_profile_batch_tensor,doppler_profil_num_tensor\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    # 分割字符串中的数字并将它们转换为整数\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def loaddata(folder_path):\n",
    "    '''\n",
    "    输入文件夹路径，输出数据集\n",
    "    '''\n",
    "    # 获取文件夹中的所有文件和子文件夹\n",
    "    items = os.listdir(folder_path)\n",
    "    # 过滤出所有文件（排除子文件夹）\n",
    "    files = [item for item in items if os.path.isfile(os.path.join(folder_path, item)) and item.endswith('.npz')]\n",
    "    files_sorted = sorted(files, key=natural_sort_key)\n",
    "    #载入数据\n",
    "    images = []\n",
    "    LOS_dirs = []\n",
    "    omegas = []\n",
    "    for file in files_sorted:\n",
    "        full_path = folder_path+\"/\"+file\n",
    "        data = np.load(full_path)\n",
    "        image = torch.from_numpy(data['image']).to(device)\n",
    "        LOS_dir = torch.from_numpy(data['LOS']).to(device)\n",
    "        omega = torch.from_numpy(data['rotation_axis']).to(device)\n",
    "        images.append(image)\n",
    "        LOS_dirs.append(LOS_dir)\n",
    "        omegas.append(omega)\n",
    "    return images,LOS_dirs,omegas\n",
    "\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "model = NeRF(input_ch = 63, input_ch_views = 27, use_viewdirs = True).to(device)\n",
    "model.load_state_dict(torch.load('/DATA/disk1/ISAR_NERF/model_state_dict50.pth'))\n",
    "model.eval()\n",
    "\n",
    "omega_real = math.pi/900\n",
    "\n",
    "folder_path = '/DATA/disk1/ISAR_NERF/asteroid_image_nerf_new/task5'\n",
    "images,LOS_dirs,omegas = loaddata(folder_path)\n",
    "\n",
    "omegas_batch_tensor,LOS_dirs_batch_tensor,range_profile_batch_tensor,doppler_profil_num_tensor = picture_sample(images,LOS_dirs,omegas,batch_size = 40)\n",
    "distance_profile_batch = batchrender(omegas_batch_tensor*omega_real,LOS_dirs_batch_tensor,model,doppler_profil_num_tensor)\n",
    "\n",
    "# print(LOS_dirs)\n",
    "# print(LOS_dirs_batch_tensor)\n",
    "\n",
    "range_image1 = distance_profile_batch.detach().cpu()\n",
    "# plt.figure()\n",
    "# plt.imshow(range_image1)\n",
    "# plt.colorbar()\n",
    "\n",
    "\n",
    "range_image2 = range_profile_batch_tensor.detach().cpu()\n",
    "# plt.figure()\n",
    "# plt.imshow(range_image2)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# 创建子图\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# 图像1\n",
    "axes[0].imshow(range_image2,cmap='hot')\n",
    "axes[0].set_title(\"groundtruth image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 图像2\n",
    "axes[1].imshow(range_image1,cmap='hot')\n",
    "axes[1].set_title(\"nerf image\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
