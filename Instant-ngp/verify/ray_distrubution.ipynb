{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[36]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 变换位置编码后的验证程序\n",
    "import torch\n",
    "import numpy as np\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "class NeRF(nn.Module):\n",
    "    def __init__(self, D=8, W=256, input_ch=3, input_ch_views=3, output_ch=2, skips=[4], use_viewdirs=True):\n",
    "        \"\"\"\n",
    "        D: 深度，多少层网络\n",
    "        W: 网络内的channel 宽度\n",
    "        input_ch: xyz的宽度\n",
    "        input_ch_views: direction的宽度\n",
    "        output_ch: 这个参数尽在 use_viewdirs=False的时候会被使用\n",
    "        skips: 类似resnet的残差连接，表明在第几层进行连接\n",
    "        use_viewdirs:\n",
    "\n",
    "        网络输入已经被位置编码后的参数，输入为[64*bs,90]，输出为[64*bs，2]，一位是体积密度，一位是后向散射系数\n",
    "        \"\"\"\n",
    "        super(NeRF, self).__init__()\n",
    "        self.D = D\n",
    "        self.W = W\n",
    "        self.input_ch = input_ch\n",
    "        self.input_ch_views = input_ch_views\n",
    "        self.skips = skips\n",
    "        self.use_viewdirs = use_viewdirs\n",
    "\n",
    "        # 神经网络,MLP\n",
    "        # 3D的空间坐标进入的网络\n",
    "        # 这个跳跃连接层是直接拼接，不是resnet的那种相加\n",
    "        self.pts_linears = nn.ModuleList(\n",
    "            [nn.Linear(input_ch, W)] + [nn.Linear(W, W) if i not in self.skips else nn.Linear(W + input_ch, W) for i in\n",
    "                                        range(D - 1)])\n",
    "\n",
    "        # 这里channel削减一半 128\n",
    "        ### Implementation according to the official code release (https://github.com/bmild/nerf/blob/master/run_nerf_helpers.py#L104-L105)\n",
    "        self.views_linears = nn.ModuleList([nn.Linear(input_ch_views + W, W // 2)])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if use_viewdirs:\n",
    "            # 特征\n",
    "            self.feature_linear = nn.Linear(W, W)\n",
    "            # 体积密度,一个值\n",
    "            self.alpha_linear = nn.Linear(W, 1)\n",
    "            # 后向散射系数，一个值\n",
    "            self.rho_linear = nn.Linear(W // 2, 1)\n",
    "        else:\n",
    "            self.output_linear = nn.Linear(W, output_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x [bs*64, 90]\n",
    "        # input_pts [bs*64, 63]\n",
    "        # input_views [bs*64,27]\n",
    "        input_pts, input_views = torch.split(x, [self.input_ch, self.input_ch_views], dim=-1)\n",
    "\n",
    "        h = input_pts\n",
    "\n",
    "        for i, l in enumerate(self.pts_linears):\n",
    "\n",
    "            h = self.pts_linears[i](h)\n",
    "            h = F.relu(h)\n",
    "            # 第四层后相加\n",
    "            if i in self.skips:\n",
    "                h = torch.cat([input_pts, h], -1)\n",
    "\n",
    "        if self.use_viewdirs:\n",
    "            # alpha只与xyz有关\n",
    "            alpha = self.alpha_linear(h)\n",
    "            feature = self.feature_linear(h)\n",
    "            # rho与xyz和d都有关\n",
    "            h = torch.cat([feature, input_views], -1)\n",
    "\n",
    "            for i, l in enumerate(self.views_linears):\n",
    "                h = self.views_linears[i](h)\n",
    "                h = F.relu(h)\n",
    "\n",
    "            sigma = self.rho_linear(h)\n",
    "            alpha = self.relu(alpha) \n",
    "            sigma = self.sigmoid(sigma)\n",
    "            outputs = torch.cat([alpha, sigma], -1)\n",
    "        else:\n",
    "            outputs = self.output_linear(h)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def batchrender(omega,LOS,model,doppler_num):\n",
    "    '''\n",
    "    omega为一个[bs,3]变量，指向旋转轴方向，模值为角速度\n",
    "    LOS为一个[bs,3]变量，方向为视线方向指向物体，模值为1\n",
    "    model是nerf模型，将一个已经进行位置编码后的位置和视线向量输入进model,可以返回这个位置的体积密度和散射系数\n",
    "    doppler_num为一个[bs]变量，确定了渲染后光线所在的位置\n",
    "    '''\n",
    "    # 确定回波波长\n",
    "    fc = torch.tensor([9.7e9]).to(device)\n",
    "    c = torch.tensor([299792458]).to(device)\n",
    "    lambda0 = c/fc\n",
    "    # 确定网格参数\n",
    "    distance_max = 60\n",
    "    distance_min = -60\n",
    "    distance_gap = 97\n",
    "    doppler_max = 15\n",
    "    doppler_min = -15\n",
    "    doppler_gap = 105\n",
    "    n_max = 30\n",
    "    n_min = -30\n",
    "    n_gap = 120\n",
    "    # 确定输入batch_size\n",
    "    batch_size,len = omega.shape\n",
    "    # 确定每个batch_size输入的投影平面\n",
    "    omega_norm = torch.linalg.norm(omega,dim = 1)\n",
    "    omega_normlize = omega/omega_norm.unsqueeze(1)\n",
    "    Doppler_vector = torch.cross(LOS,omega,dim=1)\n",
    "    LOSomega_sin_angel = torch.linalg.norm(Doppler_vector,dim=1)/(torch.linalg.norm(omega,dim=1)*torch.linalg.norm(LOS,dim=1))\n",
    "    Doppler_vector = Doppler_vector/torch.linalg.norm(Doppler_vector,dim = 1).unsqueeze(1)\n",
    "    # 绘制投影坐标\n",
    "    distance = torch.linspace(distance_min,distance_max,distance_gap).to(device)\n",
    "    distance = distance.repeat(batch_size,1)\n",
    "    distance_delta = torch.tensor((distance_max-distance_min)/distance_gap).to(device)\n",
    "    doppler = torch.linspace(doppler_min,doppler_max,doppler_gap).repeat(batch_size,1).to(device)\n",
    "    doppler = doppler*4/LOSomega_sin_angel.unsqueeze(1)\n",
    "    distance_map = distance.unsqueeze(2)*LOS.unsqueeze(1)\n",
    "    doppler_map = doppler.unsqueeze(2)*Doppler_vector.unsqueeze(1)\n",
    "    # 确定投影平面法向量\n",
    "    n = torch.cross(LOS,Doppler_vector,dim=1)\n",
    "    n = n/torch.linalg.norm(n,dim = 1).unsqueeze(1)\n",
    "    # 对投影平面法向量进行随机采样\n",
    "    n_array = torch.linspace(n_min,n_max,n_gap+1).to(device)\n",
    "    n_array = n_array.repeat(batch_size,distance_gap,1)\n",
    "    # 非随机采样\n",
    "    # n_random_array = n_array[:,:,0:-1] + (n_array[:,:,1:] - n_array[:,:,0:-1])*torch.ones(batch_size,distance_gap,n_gap).to(device)*0.5\n",
    "    # # 随机采样\n",
    "    n_random_array = n_array[:,:,0:-1] + (n_array[:,:,1:] - n_array[:,:,0:-1])*torch.rand(batch_size,distance_gap,n_gap).to(device)\n",
    "    n_random_map = n_random_array.unsqueeze(3)*n.unsqueeze(1).unsqueeze(2)\n",
    "    # 计算不同随机法向量之间的间隔\n",
    "    start_n = n.unsqueeze(1).unsqueeze(2)*torch.tensor(n_min).float().to(device)\n",
    "    start_n = start_n * torch.ones(batch_size,distance_gap,1,3).to(device)\n",
    "    n_random_map_temp = torch.cat((start_n,n_random_map),dim=2)\n",
    "    n_delta = torch.norm(n_random_map_temp[:,:,0:-1,:]-n_random_map,dim=3)\n",
    "\n",
    "    # 计算所有需要输入网络的坐标\n",
    "    code_flag = 1\n",
    "    if code_flag == 1:\n",
    "        xyz = doppler_map[torch.arange(batch_size),doppler_num,:].unsqueeze(1).unsqueeze(2) + distance_map.unsqueeze(2) + n_random_map\n",
    "        xyz_coding = positon_code_xyz(xyz)\n",
    "        LOS_coding = position_code_LOS(LOS)\n",
    "        LOS_coding = ((LOS_coding.unsqueeze(1).unsqueeze(2))*torch.ones(batch_size,distance_gap,n_gap,27).to(device)).view(-1,27)\n",
    "        xyzLOS_coding = torch.cat((xyz_coding,LOS_coding),dim=1)\n",
    "    else:\n",
    "        xyz = doppler_map[torch.arange(batch_size),doppler_num,:].unsqueeze(1).unsqueeze(2) + distance_map.unsqueeze(2) + n_random_map\n",
    "        xyz_coding = xyz.view(-1,3)\n",
    "        LOS_coding = ((LOS.unsqueeze(1).unsqueeze(2))*torch.ones(batch_size,distance_gap,n_gap,3).to(device)).view(-1,3)\n",
    "        print(LOS_coding)\n",
    "        xyzLOS_coding = torch.cat((xyz_coding,LOS_coding),dim=1)\n",
    "    output = model(xyzLOS_coding)\n",
    "    output = output.view(batch_size,distance_gap,n_gap,2)\n",
    "\n",
    "    return output[:,:,:,0]\n",
    "\n",
    "def positon_code_xyz(xyz):\n",
    "    code_len = 10\n",
    "    batch_size,distance,n,dimension = xyz.shape\n",
    "    xyz = xyz.view(-1,dimension)\n",
    "    xyz = xyz\n",
    "    position_coding = torch.zeros_like(xyz).to(device)\n",
    "    position_coding = position_coding.repeat(1,code_len*2)\n",
    "    div_term = 2 ** torch.arange(0,code_len,step=1).to(device)\n",
    "    position_coding[:,0::2] = torch.sin((xyz.unsqueeze(1) * math.pi * div_term.unsqueeze(1).unsqueeze(0)).view(batch_size*distance*n,-1))\n",
    "    position_coding[:,1::2] = torch.cos((xyz.unsqueeze(1) * math.pi * div_term.unsqueeze(1).unsqueeze(0)).view(batch_size*distance*n,-1))\n",
    "    position_coding = torch.cat((xyz,position_coding),dim=1)\n",
    "    \n",
    "    return position_coding\n",
    "\n",
    "def position_code_LOS(LOS):\n",
    "    code_len = 4\n",
    "    batch_size,dimension = LOS.shape\n",
    "    position_coding = torch.zeros_like(LOS).to(device)\n",
    "    position_coding = position_coding.repeat(1,code_len*2)\n",
    "    div_term = 2 ** torch.arange(0,code_len,step=1).to(device)\n",
    "    position_coding[:,0::2] = torch.sin((LOS.unsqueeze(1) * div_term.unsqueeze(1).unsqueeze(0)).view(batch_size,-1))\n",
    "    position_coding[:,1::2] = torch.cos((LOS.unsqueeze(1) * div_term.unsqueeze(1).unsqueeze(0)).view(batch_size,-1))\n",
    "    position_coding = torch.cat((LOS,position_coding),dim=1)\n",
    "\n",
    "    return position_coding\n",
    "\n",
    "def picture_sample(images,LOS_dirs,omegas,batch_size,image_hight = 105,image_width = 79, image_num = 37):\n",
    "    temp_num = random.sample(range(image_num),1)\n",
    "    # temp_num = [1]\n",
    "    print(temp_num)\n",
    "    temp = [t*image_hight for t in temp_num] + np.arange(100)\n",
    "    data_num = [x//image_hight for x in temp]\n",
    "    doppler_numbers = [x % image_hight for x in temp]\n",
    "    \n",
    "    LOS_dirs_batch = [LOS_dirs[x] for x in data_num]\n",
    "    omegas_batch = [omegas[x] for x in data_num]\n",
    "    range_profile_batch = [images[x][y,:] for x,y in zip(data_num,doppler_numbers)]\n",
    "\n",
    "    omegas_batch_tensor = torch.stack(omegas_batch).to(device)\n",
    "    LOS_dirs_batch_tensor = torch.stack(LOS_dirs_batch).to(device)\n",
    "    range_profile_batch_tensor = torch.stack(range_profile_batch).to(device)\n",
    "    doppler_profil_num_tensor = torch.tensor(doppler_numbers).long().to(device)\n",
    "\n",
    "    # range_image = range_profile_batch_tensor.detach().cpu()\n",
    "    # plt.imshow(range_image)\n",
    "    # plt.show()\n",
    "    \n",
    "    return omegas_batch_tensor,LOS_dirs_batch_tensor,range_profile_batch_tensor,doppler_profil_num_tensor\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    # 分割字符串中的数字并将它们转换为整数\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def loaddata(folder_path):\n",
    "    '''\n",
    "    输入文件夹路径，输出数据集\n",
    "    '''\n",
    "    # 获取文件夹中的所有文件和子文件夹\n",
    "    items = os.listdir(folder_path)\n",
    "    # 过滤出所有文件（排除子文件夹）\n",
    "    files = [item for item in items if os.path.isfile(os.path.join(folder_path, item)) and item.endswith('.npz')]\n",
    "    files_sorted = sorted(files, key=natural_sort_key)\n",
    "    #载入数据\n",
    "    images = []\n",
    "    LOS_dirs = []\n",
    "    omegas = []\n",
    "    for file in files_sorted:\n",
    "        full_path = folder_path+\"/\"+file\n",
    "        data = np.load(full_path)\n",
    "        image = torch.from_numpy(data['image']).to(device)\n",
    "        LOS_dir = torch.from_numpy(data['LOS']).to(device)\n",
    "        omega = torch.from_numpy(data['rotation_axis']).to(device)\n",
    "        images.append(image)\n",
    "        LOS_dirs.append(LOS_dir)\n",
    "        omegas.append(omega)\n",
    "    return images,LOS_dirs,omegas\n",
    "\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "model = NeRF(input_ch = 63, input_ch_views = 27, use_viewdirs = True).to(device)\n",
    "model.load_state_dict(torch.load('/DATA/disk1/ISAR_NERF/model_state_dict92.pth'))\n",
    "model.eval()\n",
    "\n",
    "omega_real = math.pi/900\n",
    "\n",
    "folder_path = '/DATA/disk1/3dmodel/3dmodel/ISAR_NERF/asteroid_image_nerf_new/real_data_reg_2024On_5'\n",
    "images,LOS_dirs,omegas = loaddata(folder_path)\n",
    "\n",
    "omegas_batch_tensor,LOS_dirs_batch_tensor,range_profile_batch_tensor,doppler_profil_num_tensor = picture_sample(images,LOS_dirs,omegas,batch_size = 40)\n",
    "output = batchrender(omegas_batch_tensor*omega_real,LOS_dirs_batch_tensor,model,doppler_profil_num_tensor)\n",
    "\n",
    "ray_distribution = output.detach().cpu()\n",
    "ray_distribution_one = ray_distribution[40,60,:]\n",
    "\n",
    "# 绘制图像\n",
    "plt.figure()\n",
    "plt.plot(ray_distribution_one)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
